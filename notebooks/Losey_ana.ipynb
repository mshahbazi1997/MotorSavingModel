{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../../latent_analysis/'))\n",
    "sys.path.append(os.path.abspath('../../dPCA/python/'))\n",
    "import LTransform as LT\n",
    "from dPCA import dPCA\n",
    "from pathlib import Path\n",
    "from model import test\n",
    "from utils import create_directory, load_stuff\n",
    "import numpy as np\n",
    "import torch as th\n",
    "import plot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n"
     ]
    }
   ],
   "source": [
    "# Load hidden\n",
    "data_dir = create_directory(directory_name='loss20')\n",
    "model_num = 0\n",
    "model_name = \"model{:02d}\".format(model_num)\n",
    "\n",
    "all_hidden = []\n",
    "ff = [0,8,0,8]\n",
    "\n",
    "data = []\n",
    "for i, phase in enumerate(['NF1','FF1','NF2','FF2']):\n",
    "\n",
    "    weight_file = list(Path(data_dir).glob(f'{model_name}_phase={phase}_*_weights'))[0]\n",
    "    cfg_file = list(Path(data_dir).glob(f'{model_name}_phase={phase}_*_cfg.json'))[0]\n",
    "\n",
    "    env, policy, _, _ = load_stuff(cfg_file,weight_file,phase=phase)\n",
    "    data0, loss, ang_dev, lat_dev = test(env,policy,ff_coefficient=ff[i],is_channel=False)\n",
    "    data.append(np.array(data0['all_hidden']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SVD\n",
    "n_muscle = 6\n",
    "n_latent = 3\n",
    "\n",
    "W = th.load(weight_file)['fc.weight'].numpy()\n",
    "U, S, Vh = np.linalg.svd(W, full_matrices=True)\n",
    "V = Vh.T\n",
    "P = V[:,:n_muscle] # output potent\n",
    "N = V[:,n_muscle:] # output null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_prep =  {'x_pot_ld':[],'x_null_ld':[]}\n",
    "for i in range(4):\n",
    "    U=data[i]\n",
    "    dims=U.shape\n",
    "\n",
    "    X = U-np.mean(U,axis=0,keepdims=True) # TODO\n",
    "    X = X.reshape(-1,dims[-1]) # [(cond X time), neuron]\n",
    "    X = X-np.mean(X,axis=0)\n",
    "\n",
    "    X_pot = X@(P) # @P.T\n",
    "    X_null = X@(N) # @N.T\n",
    "\n",
    "    X_pot = np.reshape(X_pot,newshape=dims[:-1]+(n_muscle,))\n",
    "    X_null = np.reshape(X_null,newshape=dims[:-1]+(dims[-1]-n_muscle,))\n",
    "    X = np.reshape(X,newshape=dims)\n",
    "\n",
    "    if i==0:\n",
    "        T_p = LT.Transform(num_latent=n_latent)\n",
    "        T_l = LT.Transform(num_latent=n_latent) \n",
    "\n",
    "        T_p.fit(X_pot,method='PCA')\n",
    "        T_l.fit(X_null,method='PCA')\n",
    "\n",
    "    x_pot_ld = T_p.transform(X_pot,ensure_orthogonality=True)\n",
    "    x_null_ld = T_l.transform(X_null,ensure_orthogonality=True)\n",
    "\n",
    "    Data_prep['x_pot_ld'].append(x_pot_ld)\n",
    "    Data_prep['x_null_ld'].append(x_null_ld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "fig, ax = plot.plot_traj([Data_prep['x_null_ld'][0], Data_prep['x_null_ld'][1]],which_times=[10],plot_scatter=1,dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
