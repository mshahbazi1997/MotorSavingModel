{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys \n",
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model00...\n",
      "model01...\n",
      "model02...\n",
      "model03...\n",
      "model04...\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "Training growing_up:   0%|                         | 0/20010 [00:00<?, ?batch/s]skipping cudagraphs for unknown reason\n",
      "Training growing_up:   0%|                         | 0/20010 [00:00<?, ?batch/s]skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "Training growing_up:   0%|                         | 0/20010 [00:00<?, ?batch/s]skipping cudagraphs for unknown reason\n",
      "Training growing_up:   0%|                         | 0/20010 [00:00<?, ?batch/s]skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "skipping cudagraphs for unknown reason\n",
      "Training growing_up:   0%|             | 100/20010 [00:33<1:30:26,  3.67batch/s]Batch 100/20010 Done, mean position loss: 164.09061665058135\n",
      "Training growing_up:   0%|             | 100/20010 [00:33<1:30:44,  3.66batch/s]Batch 100/20010 Done, mean position loss: 125.44905909061431\n",
      "Training growing_up:   0%|             | 100/20010 [00:33<1:26:10,  3.85batch/s]Batch 100/20010 Done, mean position loss: 148.59012041568758\n",
      "Training growing_up:   1%|             | 102/20010 [00:33<1:23:02,  4.00batch/s]Batch 100/20010 Done, mean position loss: 116.40629850387572\n",
      "Training growing_up:   1%|             | 102/20010 [00:33<1:24:23,  3.93batch/s]Batch 100/20010 Done, mean position loss: 115.03149143218995\n",
      "Training growing_up:   1%|▏            | 198/20010 [00:57<1:21:31,  4.05batch/s]Batch 200/20010 Done, mean position loss: 184.75450382232668\n",
      "Training growing_up:   1%|▏            | 200/20010 [00:58<1:27:00,  3.79batch/s]Batch 200/20010 Done, mean position loss: 114.18216553211212\n",
      "Training growing_up:   1%|▏            | 201/20010 [00:58<1:25:40,  3.85batch/s]Batch 200/20010 Done, mean position loss: 118.97652805328367\n",
      "Training growing_up:   1%|▏            | 203/20010 [00:58<1:20:05,  4.12batch/s]Batch 200/20010 Done, mean position loss: 112.87364117622376\n",
      "Training growing_up:   1%|▏            | 202/20010 [00:58<1:23:34,  3.95batch/s]Batch 200/20010 Done, mean position loss: 119.42876886844635\n",
      "Training growing_up:   1%|▏            | 298/20010 [01:22<1:20:20,  4.09batch/s]Batch 300/20010 Done, mean position loss: 119.52003105640412\n",
      "Training growing_up:   2%|▏            | 303/20010 [01:23<1:20:25,  4.08batch/s]Batch 300/20010 Done, mean position loss: 100.56167775154114\n",
      "Training growing_up:   2%|▏            | 301/20010 [01:23<1:23:41,  3.93batch/s]Batch 300/20010 Done, mean position loss: 97.40262540817261\n",
      "Training growing_up:   2%|▏            | 301/20010 [01:23<1:23:38,  3.93batch/s]Batch 300/20010 Done, mean position loss: 111.2497893190384\n",
      "Training growing_up:   2%|▏            | 304/20010 [01:23<1:20:09,  4.10batch/s]Batch 300/20010 Done, mean position loss: 133.0662697172165\n",
      "Training growing_up:   2%|▎            | 393/20010 [01:47<1:24:19,  3.88batch/s]Batch 400/20010 Done, mean position loss: 91.78280520439148\n",
      "Training growing_up:   2%|▎            | 396/20010 [01:47<1:21:36,  4.01batch/s]Batch 400/20010 Done, mean position loss: 100.60016905784607\n",
      "Batch 400/20010 Done, mean position loss: 88.54958910226821\n",
      "Training growing_up:   2%|▎            | 401/20010 [01:47<1:22:55,  3.94batch/s]Batch 400/20010 Done, mean position loss: 91.88021774291991\n",
      "Training growing_up:   2%|▎            | 406/20010 [01:49<1:20:45,  4.05batch/s]Batch 400/20010 Done, mean position loss: 112.7393765258789\n",
      "Training growing_up:   2%|▎            | 491/20010 [02:11<1:26:57,  3.74batch/s]Batch 500/20010 Done, mean position loss: 94.65935598373412\n",
      "Training growing_up:   3%|▎            | 505/20010 [02:12<1:17:46,  4.18batch/s]Batch 500/20010 Done, mean position loss: 99.43306980133057\n",
      "Training growing_up:   3%|▎            | 501/20010 [02:12<1:22:48,  3.93batch/s]Batch 500/20010 Done, mean position loss: 100.64423446655275\n",
      "Training growing_up:   3%|▎            | 506/20010 [02:13<1:24:52,  3.83batch/s]Batch 500/20010 Done, mean position loss: 90.66208828449248\n",
      "Training growing_up:   3%|▎            | 507/20010 [02:14<1:23:16,  3.90batch/s]Batch 500/20010 Done, mean position loss: 112.4725104188919\n",
      "Training growing_up:   3%|▍            | 589/20010 [02:36<1:18:56,  4.10batch/s]Batch 600/20010 Done, mean position loss: 81.5996793603897\n",
      "Training growing_up:   3%|▍            | 593/20010 [02:37<1:21:36,  3.97batch/s]Batch 600/20010 Done, mean position loss: 87.75216271400453\n",
      "Training growing_up:   3%|▍            | 602/20010 [02:37<1:21:00,  3.99batch/s]Batch 600/20010 Done, mean position loss: 100.77005174636841\n",
      "Training growing_up:   3%|▍            | 608/20010 [02:38<1:20:48,  4.00batch/s]Batch 600/20010 Done, mean position loss: 72.82184787034988\n",
      "Training growing_up:   3%|▍            | 613/20010 [02:39<1:17:06,  4.19batch/s]Batch 600/20010 Done, mean position loss: 75.53720124721528\n",
      "Training growing_up:   3%|▍            | 687/20010 [03:01<1:19:20,  4.06batch/s]Batch 700/20010 Done, mean position loss: 73.0596291899681\n",
      "Training growing_up:   3%|▍            | 699/20010 [03:02<1:25:17,  3.77batch/s]Batch 700/20010 Done, mean position loss: 75.26056718349457\n",
      "Training growing_up:   3%|▍            | 699/20010 [03:03<1:25:16,  3.77batch/s]Batch 700/20010 Done, mean position loss: 100.55015152931213\n",
      "Training growing_up:   4%|▍            | 710/20010 [03:03<1:18:50,  4.08batch/s]Batch 700/20010 Done, mean position loss: 83.50248721599579\n",
      "Training growing_up:   4%|▍            | 709/20010 [03:04<1:21:54,  3.93batch/s]Batch 700/20010 Done, mean position loss: 82.94834085464478\n",
      "Training growing_up:   4%|▌            | 795/20010 [03:25<1:18:10,  4.10batch/s]Batch 800/20010 Done, mean position loss: 71.8107275748253\n",
      "Training growing_up:   4%|▌            | 798/20010 [03:27<1:17:40,  4.12batch/s]Batch 800/20010 Done, mean position loss: 77.45396028280258\n",
      "Training growing_up:   4%|▌            | 794/20010 [03:28<1:21:20,  3.94batch/s]Batch 800/20010 Done, mean position loss: 131.4921631193161\n",
      "Training growing_up:   4%|▌            | 806/20010 [03:28<1:17:37,  4.12batch/s]Batch 800/20010 Done, mean position loss: 76.99841666698455\n",
      "Training growing_up:   4%|▌            | 816/20010 [03:29<1:19:20,  4.03batch/s]Batch 800/20010 Done, mean position loss: 66.88039513349534\n",
      "Training growing_up:   4%|▌            | 884/20010 [03:50<1:23:15,  3.83batch/s]Batch 900/20010 Done, mean position loss: 61.396795151233675\n",
      "Training growing_up:   4%|▌            | 895/20010 [03:52<1:18:41,  4.05batch/s]Batch 900/20010 Done, mean position loss: 55.8002464222908\n",
      "Training growing_up:   5%|▌            | 911/20010 [03:53<1:17:30,  4.11batch/s]Batch 900/20010 Done, mean position loss: 121.43285816669464\n",
      "Training growing_up:   5%|▌            | 903/20010 [03:53<1:18:15,  4.07batch/s]Batch 900/20010 Done, mean position loss: 57.099948151111604\n",
      "Training growing_up:   5%|▌            | 918/20010 [03:54<1:17:54,  4.08batch/s]Batch 900/20010 Done, mean position loss: 61.86968846321106\n",
      "Training growing_up:   5%|▋            | 987/20010 [04:15<1:18:31,  4.04batch/s]Batch 1000/20010 Done, mean position loss: 61.08063599348068\n",
      "Training growing_up:   5%|▋            | 997/20010 [04:17<1:16:39,  4.13batch/s]Batch 1000/20010 Done, mean position loss: 53.39423487901688\n",
      "Training growing_up:   5%|▋            | 992/20010 [04:18<1:22:43,  3.83batch/s]Batch 1000/20010 Done, mean position loss: 98.17168575048447\n",
      "Training growing_up:   5%|▋            | 995/20010 [04:18<1:19:07,  4.01batch/s]Batch 1000/20010 Done, mean position loss: 54.08292014598847\n",
      "Training growing_up:   5%|▌           | 1021/20010 [04:20<1:15:33,  4.19batch/s]Batch 1000/20010 Done, mean position loss: 63.51211989164352\n",
      "Training growing_up:   5%|▋           | 1092/20010 [04:39<1:22:12,  3.84batch/s]Batch 1100/20010 Done, mean position loss: 55.028737597465515\n",
      "Training growing_up:   5%|▋           | 1087/20010 [04:42<1:19:01,  3.99batch/s]Batch 1100/20010 Done, mean position loss: 53.021347892284396\n",
      "Training growing_up:   6%|▋           | 1114/20010 [04:43<1:14:40,  4.22batch/s]Batch 1100/20010 Done, mean position loss: 82.49014917135239\n",
      "Training growing_up:   6%|▋           | 1104/20010 [04:44<1:18:35,  4.01batch/s]Batch 1100/20010 Done, mean position loss: 51.638080723285675\n",
      "Training growing_up:   6%|▋           | 1107/20010 [04:45<1:23:36,  3.77batch/s]Batch 1100/20010 Done, mean position loss: 51.5824801492691\n",
      "Training growing_up:   6%|▋           | 1187/20010 [05:04<1:17:39,  4.04batch/s]Batch 1200/20010 Done, mean position loss: 42.2898633646965\n",
      "Training growing_up:   6%|▋           | 1210/20010 [05:07<1:17:04,  4.07batch/s]Batch 1200/20010 Done, mean position loss: 45.07023896694183\n",
      "Training growing_up:   6%|▋           | 1215/20010 [05:08<1:19:53,  3.92batch/s]Batch 1200/20010 Done, mean position loss: 71.25218532562256\n",
      "Training growing_up:   6%|▋           | 1209/20010 [05:09<1:19:07,  3.96batch/s]Batch 1200/20010 Done, mean position loss: 48.46885034322739\n",
      "Training growing_up:   6%|▋           | 1216/20010 [05:10<1:18:39,  3.98batch/s]Batch 1200/20010 Done, mean position loss: 45.533322880268095\n",
      "Training growing_up:   6%|▊           | 1291/20010 [05:29<1:14:33,  4.18batch/s]Batch 1300/20010 Done, mean position loss: 48.33969643115997\n",
      "Training growing_up:   6%|▊           | 1292/20010 [05:32<1:22:02,  3.80batch/s]Batch 1300/20010 Done, mean position loss: 47.809455156326294\n",
      "Training growing_up:   6%|▊           | 1290/20010 [05:33<1:16:40,  4.07batch/s]Batch 1300/20010 Done, mean position loss: 60.64924686670304\n",
      "Training growing_up:   7%|▊           | 1320/20010 [05:34<1:14:41,  4.17batch/s]Batch 1300/20010 Done, mean position loss: 44.28877824068069\n",
      "Training growing_up:   7%|▊           | 1312/20010 [05:36<1:15:34,  4.12batch/s]Batch 1300/20010 Done, mean position loss: 37.619079604148865\n",
      "Training growing_up:   7%|▊           | 1390/20010 [05:54<1:15:15,  4.12batch/s]Batch 1400/20010 Done, mean position loss: 47.04205425262451\n",
      "Training growing_up:   7%|▊           | 1412/20010 [05:57<1:14:57,  4.13batch/s]Batch 1400/20010 Done, mean position loss: 41.156083645820615\n",
      "Training growing_up:   7%|▊           | 1397/20010 [05:58<1:15:57,  4.08batch/s]Batch 1400/20010 Done, mean position loss: 54.584068353176114\n",
      "Training growing_up:   7%|▊           | 1405/20010 [05:59<1:17:33,  4.00batch/s]Batch 1400/20010 Done, mean position loss: 50.289942898750304\n",
      "Training growing_up:   7%|▊           | 1409/20010 [06:01<1:20:52,  3.83batch/s]Batch 1400/20010 Done, mean position loss: 39.497616946697235\n",
      "Training growing_up:   7%|▉           | 1470/20010 [06:19<1:18:57,  3.91batch/s]Batch 1500/20010 Done, mean position loss: 41.885437335968014\n",
      "Training growing_up:   7%|▉           | 1490/20010 [06:21<1:15:35,  4.08batch/s]Batch 1500/20010 Done, mean position loss: 40.519156286716466\n",
      "Training growing_up:   7%|▉           | 1496/20010 [06:23<1:14:54,  4.12batch/s]Batch 1500/20010 Done, mean position loss: 50.62381655216217\n",
      "Training growing_up:   8%|▉           | 1506/20010 [06:24<1:14:35,  4.13batch/s]Batch 1500/20010 Done, mean position loss: 44.88546744585037\n",
      "Training growing_up:   8%|▉           | 1532/20010 [06:26<1:17:17,  3.98batch/s]Batch 1500/20010 Done, mean position loss: 41.928293507099156\n",
      "Training growing_up:   8%|▉           | 1582/20010 [06:43<1:16:15,  4.03batch/s]Batch 1600/20010 Done, mean position loss: 42.00531363010407\n",
      "Training growing_up:   8%|▉           | 1580/20010 [06:46<1:16:02,  4.04batch/s]Batch 1600/20010 Done, mean position loss: 44.134006917476654\n",
      "Training growing_up:   8%|▉           | 1620/20010 [06:48<1:13:40,  4.16batch/s]Batch 1600/20010 Done, mean position loss: 47.3305337023735\n",
      "Training growing_up:   8%|▉           | 1605/20010 [06:49<1:16:15,  4.02batch/s]Batch 1600/20010 Done, mean position loss: 42.097451102733615\n",
      "Training growing_up:   8%|▉           | 1622/20010 [06:52<1:14:10,  4.13batch/s]Batch 1600/20010 Done, mean position loss: 43.18687443494797\n",
      "Training growing_up:   8%|█           | 1680/20010 [07:08<1:15:01,  4.07batch/s]Batch 1700/20010 Done, mean position loss: 40.26544255495071\n",
      "Training growing_up:   8%|█           | 1689/20010 [07:11<1:14:47,  4.08batch/s]Batch 1700/20010 Done, mean position loss: 43.263471567630766\n",
      "Training growing_up:   8%|█           | 1685/20010 [07:13<1:19:09,  3.86batch/s]Batch 1700/20010 Done, mean position loss: 47.937316777706144\n",
      "Training growing_up:   9%|█           | 1705/20010 [07:14<1:14:25,  4.10batch/s]Batch 1700/20010 Done, mean position loss: 39.44259115934372\n",
      "Training growing_up:   9%|█           | 1738/20010 [07:17<1:20:23,  3.79batch/s]Batch 1700/20010 Done, mean position loss: 36.861711826324466\n",
      "Training growing_up:   9%|█           | 1787/20010 [07:32<1:16:16,  3.98batch/s]Batch 1800/20010 Done, mean position loss: 38.77935322999954\n",
      "Training growing_up:   9%|█           | 1793/20010 [07:36<1:22:39,  3.67batch/s]Batch 1800/20010 Done, mean position loss: 38.16217037200927\n",
      "Training growing_up:   9%|█           | 1823/20010 [07:38<1:13:13,  4.14batch/s]Batch 1800/20010 Done, mean position loss: 46.796037740707405\n",
      "Training growing_up:   9%|█           | 1789/20010 [07:39<1:14:51,  4.06batch/s]Batch 1800/20010 Done, mean position loss: 42.105112001895904\n",
      "Training growing_up:   9%|█           | 1817/20010 [07:42<1:18:03,  3.88batch/s]Batch 1800/20010 Done, mean position loss: 39.370237965583804\n",
      "Training growing_up:   9%|█▏          | 1886/20010 [07:57<1:20:46,  3.74batch/s]Batch 1900/20010 Done, mean position loss: 41.500864996910096\n",
      "Training growing_up:   9%|█▏          | 1892/20010 [08:01<1:13:03,  4.13batch/s]Batch 1900/20010 Done, mean position loss: 38.519535286426546\n",
      "Training growing_up:   9%|█▏          | 1884/20010 [08:03<1:14:11,  4.07batch/s]Batch 1900/20010 Done, mean position loss: 45.539002287387845\n",
      "Training growing_up:  10%|█▏          | 1905/20010 [08:04<1:15:47,  3.98batch/s]Batch 1900/20010 Done, mean position loss: 38.72093101263046\n",
      "Training growing_up:  10%|█▏          | 1927/20010 [08:07<1:15:11,  4.01batch/s]Batch 1900/20010 Done, mean position loss: 37.05117841482162\n",
      "Training growing_up:  10%|█▏          | 1958/20010 [08:22<1:15:27,  3.99batch/s]Batch 2000/20010 Done, mean position loss: 38.64207869529724\n",
      "Training growing_up:  10%|█▏          | 1991/20010 [08:26<1:14:13,  4.05batch/s]Batch 2000/20010 Done, mean position loss: 39.05381840229035\n",
      "Training growing_up:  10%|█▏          | 1983/20010 [08:28<1:14:30,  4.03batch/s]Batch 2000/20010 Done, mean position loss: 45.22688752174378\n",
      "Training growing_up:  10%|█▏          | 2006/20010 [08:30<1:13:33,  4.08batch/s]Batch 2000/20010 Done, mean position loss: 37.41397860527039\n",
      "Training growing_up:  10%|█▏          | 2013/20010 [08:33<1:15:24,  3.98batch/s]Batch 2000/20010 Done, mean position loss: 36.7496581363678\n",
      "Training growing_up:  10%|█▏          | 2069/20010 [08:47<1:12:28,  4.13batch/s]Batch 2100/20010 Done, mean position loss: 39.243357791900635\n",
      "Training growing_up:  10%|█▎          | 2085/20010 [08:51<1:13:05,  4.09batch/s]Batch 2100/20010 Done, mean position loss: 40.58843672990799\n",
      "Training growing_up:  11%|█▎          | 2111/20010 [08:53<1:12:52,  4.09batch/s]Batch 2100/20010 Done, mean position loss: 43.2365203166008\n",
      "Training growing_up:  11%|█▎          | 2106/20010 [08:55<1:16:21,  3.91batch/s]Batch 2100/20010 Done, mean position loss: 42.23240768432617\n",
      "Training growing_up:  11%|█▎          | 2146/20010 [08:58<1:13:23,  4.06batch/s]Batch 2100/20010 Done, mean position loss: 37.536028339862824\n",
      "Training growing_up:  11%|█▎          | 2154/20010 [09:11<1:14:42,  3.98batch/s]Batch 2200/20010 Done, mean position loss: 37.43568043947219\n",
      "Training growing_up:  11%|█▎          | 2171/20010 [09:16<1:12:58,  4.07batch/s]Batch 2200/20010 Done, mean position loss: 37.22006900548935\n",
      "Training growing_up:  11%|█▎          | 2211/20010 [09:18<1:11:26,  4.15batch/s]Batch 2200/20010 Done, mean position loss: 39.2590167760849\n",
      "Training growing_up:  11%|█▎          | 2217/20010 [09:20<1:11:45,  4.13batch/s]Batch 2200/20010 Done, mean position loss: 39.33088336467743\n",
      "Training growing_up:  11%|█▎          | 2220/20010 [09:23<1:11:42,  4.14batch/s]Batch 2200/20010 Done, mean position loss: 35.619755489826204\n",
      "Training growing_up:  11%|█▎          | 2283/20010 [09:36<1:17:55,  3.79batch/s]Batch 2300/20010 Done, mean position loss: 37.09219768285751\n",
      "Training growing_up:  11%|█▎          | 2289/20010 [09:40<1:13:08,  4.04batch/s]Batch 2300/20010 Done, mean position loss: 37.397760100364685\n",
      "Training growing_up:  12%|█▍          | 2330/20010 [09:43<1:17:06,  3.82batch/s]Batch 2300/20010 Done, mean position loss: 38.22315918207168\n",
      "Training growing_up:  12%|█▍          | 2318/20010 [09:45<1:11:16,  4.14batch/s]Batch 2300/20010 Done, mean position loss: 38.141516828536986\n",
      "Training growing_up:  12%|█▍          | 2320/20010 [09:48<1:11:20,  4.13batch/s]Batch 2300/20010 Done, mean position loss: 37.4001482629776\n",
      "Training growing_up:  12%|█▍          | 2365/20010 [10:01<1:13:16,  4.01batch/s]Batch 2400/20010 Done, mean position loss: 34.432337994575505\n",
      "Training growing_up:  12%|█▍          | 2383/20010 [10:06<1:11:58,  4.08batch/s]Batch 2400/20010 Done, mean position loss: 35.62665914773941\n",
      "Training growing_up:  12%|█▍          | 2381/20010 [10:08<1:13:09,  4.02batch/s]Batch 2400/20010 Done, mean position loss: 38.08298608064652\n",
      "Training growing_up:  12%|█▍          | 2419/20010 [10:10<1:12:02,  4.07batch/s]Batch 2400/20010 Done, mean position loss: 38.22135764360428\n",
      "Training growing_up:  12%|█▍          | 2421/20010 [10:14<1:11:54,  4.08batch/s]Batch 2400/20010 Done, mean position loss: 40.4982976937294\n",
      "Training growing_up:  12%|█▍          | 2463/20010 [10:26<1:15:33,  3.87batch/s]Batch 2500/20010 Done, mean position loss: 38.61627661943436\n",
      "Training growing_up:  12%|█▍          | 2468/20010 [10:30<1:11:53,  4.07batch/s]Batch 2500/20010 Done, mean position loss: 36.64383086681366\n",
      "Training growing_up:  13%|█▌          | 2532/20010 [10:33<1:15:41,  3.85batch/s]Batch 2500/20010 Done, mean position loss: 36.662620544433594\n",
      "Training growing_up:  13%|█▌          | 2507/20010 [10:35<1:12:12,  4.04batch/s]Batch 2500/20010 Done, mean position loss: 34.681648430824275\n",
      "Training growing_up:  13%|█▌          | 2515/20010 [10:39<1:11:39,  4.07batch/s]Batch 2500/20010 Done, mean position loss: 37.00186938047409\n",
      "Training growing_up:  13%|█▌          | 2547/20010 [10:50<1:10:38,  4.12batch/s]Batch 2600/20010 Done, mean position loss: 36.350606076717376\n",
      "Training growing_up:  13%|█▌          | 2621/20010 [10:55<1:10:29,  4.11batch/s]Batch 2600/20010 Done, mean position loss: 33.95248025894165\n",
      "Training growing_up:  13%|█▌          | 2634/20010 [10:59<1:16:10,  3.80batch/s]Batch 2600/20010 Done, mean position loss: 36.015902602672575\n",
      "Training growing_up:  13%|█▌          | 2607/20010 [11:00<1:12:48,  3.98batch/s]Batch 2600/20010 Done, mean position loss: 34.08409592151642\n",
      "Training growing_up:  13%|█▌          | 2615/20010 [11:04<1:10:28,  4.11batch/s]Batch 2600/20010 Done, mean position loss: 35.370862588882446\n",
      "Training growing_up:  13%|█▌          | 2666/20010 [11:15<1:14:10,  3.90batch/s]Batch 2700/20010 Done, mean position loss: 40.7496650314331\n",
      "Training growing_up:  14%|█▋          | 2722/20010 [11:20<1:11:43,  4.02batch/s]Batch 2700/20010 Done, mean position loss: 35.65493903636933\n",
      "Training growing_up:  14%|█▋          | 2714/20010 [11:24<1:11:17,  4.04batch/s]Batch 2700/20010 Done, mean position loss: 36.51756147146225\n",
      "Training growing_up:  13%|█▌          | 2686/20010 [11:25<1:12:14,  4.00batch/s]Batch 2700/20010 Done, mean position loss: 36.20215260744095\n",
      "Training growing_up:  14%|█▋          | 2722/20010 [11:29<1:11:18,  4.04batch/s]Batch 2700/20010 Done, mean position loss: 37.35549322605134\n",
      "Training growing_up:  14%|█▋          | 2765/20010 [11:40<1:10:19,  4.09batch/s]Batch 2800/20010 Done, mean position loss: 37.124162185192105\n",
      "Training growing_up:  14%|█▋          | 2786/20010 [11:45<1:11:06,  4.04batch/s]Batch 2800/20010 Done, mean position loss: 35.123439619541166\n",
      "Training growing_up:  14%|█▋          | 2779/20010 [11:49<1:11:25,  4.02batch/s]Batch 2800/20010 Done, mean position loss: 35.962449662685394\n",
      "Training growing_up:  14%|█▋          | 2822/20010 [11:50<1:13:50,  3.88batch/s]Batch 2800/20010 Done, mean position loss: 37.129186530113216\n",
      "Training growing_up:  14%|█▋          | 2816/20010 [11:54<1:10:13,  4.08batch/s]Batch 2800/20010 Done, mean position loss: 38.10986552476883\n",
      "Training growing_up:  14%|█▋          | 2841/20010 [12:05<1:09:55,  4.09batch/s]Batch 2900/20010 Done, mean position loss: 34.457868375778204\n",
      "Training growing_up:  15%|█▊          | 2923/20010 [12:10<1:13:39,  3.87batch/s]Batch 2900/20010 Done, mean position loss: 40.24533171176911\n",
      "Training growing_up:  15%|█▊          | 2938/20010 [12:14<1:15:39,  3.76batch/s]Batch 2900/20010 Done, mean position loss: 35.77528226613998\n",
      "Training growing_up:  14%|█▋          | 2884/20010 [12:15<1:14:10,  3.85batch/s]Batch 2900/20010 Done, mean position loss: 35.28522296905518\n",
      "Training growing_up:  15%|█▊          | 2961/20010 [12:20<1:14:45,  3.80batch/s]Batch 2900/20010 Done, mean position loss: 36.03015468597412\n",
      "Training growing_up:  15%|█▊          | 2978/20010 [12:29<1:12:22,  3.92batch/s]Batch 3000/20010 Done, mean position loss: 33.80733254671097\n",
      "Training growing_up:  15%|█▊          | 2962/20010 [12:35<1:13:15,  3.88batch/s]Batch 3000/20010 Done, mean position loss: 36.20643825054169\n",
      "Training growing_up:  15%|█▊          | 2978/20010 [12:39<1:13:34,  3.86batch/s]Batch 3000/20010 Done, mean position loss: 37.18635455846786\n",
      "Training growing_up:  15%|█▊          | 3023/20010 [12:41<1:08:44,  4.12batch/s]Batch 3000/20010 Done, mean position loss: 33.965872049331665\n",
      "Training growing_up:  15%|█▊          | 3063/20010 [12:45<1:07:45,  4.17batch/s]Batch 3000/20010 Done, mean position loss: 33.7818598818779\n",
      "Training growing_up:  15%|█▊          | 3038/20010 [12:54<1:10:02,  4.04batch/s]Batch 3100/20010 Done, mean position loss: 36.41856747865677\n",
      "Training growing_up:  15%|█▊          | 3078/20010 [13:00<1:09:18,  4.07batch/s]Batch 3100/20010 Done, mean position loss: 36.20800767660141\n",
      "Training growing_up:  16%|█▊          | 3118/20010 [13:04<1:07:40,  4.16batch/s]Batch 3100/20010 Done, mean position loss: 33.83241085767746\n",
      "Training growing_up:  16%|█▉          | 3148/20010 [13:06<1:08:46,  4.09batch/s]Batch 3100/20010 Done, mean position loss: 40.615195152759554\n",
      "Training growing_up:  16%|█▉          | 3165/20010 [13:10<1:09:04,  4.06batch/s]Batch 3100/20010 Done, mean position loss: 36.44617025136948\n",
      "Training growing_up:  16%|█▉          | 3153/20010 [13:19<1:11:06,  3.95batch/s]Batch 3200/20010 Done, mean position loss: 36.24711071968079\n",
      "Training growing_up:  16%|█▉          | 3225/20010 [13:25<1:10:01,  3.99batch/s]Batch 3200/20010 Done, mean position loss: 35.47837638616562\n",
      "Training growing_up:  16%|█▉          | 3243/20010 [13:30<1:08:31,  4.08batch/s]Batch 3200/20010 Done, mean position loss: 39.96221461057662\n",
      "Training growing_up:  16%|█▉          | 3249/20010 [13:31<1:10:15,  3.98batch/s]Batch 3200/20010 Done, mean position loss: 34.3088375711441\n",
      "Training growing_up:  16%|█▉          | 3225/20010 [13:36<1:13:26,  3.81batch/s]Batch 3200/20010 Done, mean position loss: 33.46734865665436\n",
      "Training growing_up:  16%|█▉          | 3257/20010 [13:44<1:12:02,  3.88batch/s]Batch 3300/20010 Done, mean position loss: 33.10787931680679\n",
      "Training growing_up:  17%|█▉          | 3326/20010 [13:50<1:07:09,  4.14batch/s]Batch 3300/20010 Done, mean position loss: 34.69386908769607\n",
      "Training growing_up:  16%|█▉          | 3295/20010 [13:55<1:07:17,  4.14batch/s]Batch 3300/20010 Done, mean position loss: 34.00665819883346\n",
      "Training growing_up:  16%|█▉          | 3281/20010 [13:56<1:13:01,  3.82batch/s]Batch 3300/20010 Done, mean position loss: 36.91463054418564\n",
      "Training growing_up:  17%|██          | 3345/20010 [14:01<1:11:28,  3.89batch/s]Batch 3300/20010 Done, mean position loss: 33.98157870054245\n",
      "Training growing_up:  17%|██          | 3356/20010 [14:09<1:08:15,  4.07batch/s]Batch 3400/20010 Done, mean position loss: 31.295372960567477\n",
      "Training growing_up:  17%|██          | 3376/20010 [14:15<1:13:52,  3.75batch/s]Batch 3400/20010 Done, mean position loss: 35.225771532058715\n",
      "Training growing_up:  17%|██          | 3446/20010 [14:20<1:05:32,  4.21batch/s]Batch 3400/20010 Done, mean position loss: 35.25705471277237\n",
      "Training growing_up:  17%|██          | 3380/20010 [14:21<1:07:17,  4.12batch/s]Batch 3400/20010 Done, mean position loss: 34.87982609033584\n",
      "Training growing_up:  17%|██          | 3422/20010 [14:27<1:07:30,  4.10batch/s]Batch 3400/20010 Done, mean position loss: 35.10089667320251\n",
      "Training growing_up:  17%|██          | 3449/20010 [14:33<1:10:03,  3.94batch/s]Batch 3500/20010 Done, mean position loss: 32.650082380771636\n",
      "Training growing_up:  17%|██          | 3454/20010 [14:40<1:07:34,  4.08batch/s]Batch 3500/20010 Done, mean position loss: 36.91644743442535\n",
      "Training growing_up:  17%|██          | 3495/20010 [14:45<1:13:12,  3.76batch/s]Batch 3500/20010 Done, mean position loss: 32.43561872959137\n",
      "Training growing_up:  17%|██          | 3479/20010 [14:46<1:13:36,  3.74batch/s]Batch 3500/20010 Done, mean position loss: 33.44027683019638\n",
      "Training growing_up:  18%|██          | 3528/20010 [14:52<1:11:34,  3.84batch/s]Batch 3500/20010 Done, mean position loss: 34.89250442028046\n",
      "Training growing_up:  18%|██▏         | 3553/20010 [14:58<1:09:58,  3.92batch/s]Batch 3600/20010 Done, mean position loss: 31.72412524461746\n",
      "Training growing_up:  18%|██▏         | 3575/20010 [15:05<1:14:19,  3.69batch/s]Batch 3600/20010 Done, mean position loss: 32.881124243736274\n",
      "Training growing_up:  18%|██▏         | 3595/20010 [15:10<1:10:14,  3.89batch/s]Batch 3600/20010 Done, mean position loss: 32.30290758609772\n",
      "Training growing_up:  18%|██▏         | 3578/20010 [15:11<1:07:49,  4.04batch/s]Batch 3600/20010 Done, mean position loss: 33.71661409854889\n",
      "Training growing_up:  18%|██▏         | 3649/20010 [15:17<1:10:23,  3.87batch/s]Batch 3600/20010 Done, mean position loss: 34.05580411672592\n",
      "Training growing_up:  18%|██▏         | 3646/20010 [15:23<1:06:36,  4.09batch/s]Batch 3700/20010 Done, mean position loss: 33.06128710269928\n",
      "Training growing_up:  18%|██▏         | 3652/20010 [15:30<1:07:06,  4.06batch/s]Batch 3700/20010 Done, mean position loss: 34.04360523223877\n",
      "Training growing_up:  18%|██▏         | 3672/20010 [15:35<1:10:06,  3.88batch/s]Batch 3700/20010 Done, mean position loss: 31.963111073970794\n",
      "Training growing_up:  19%|██▏         | 3727/20010 [15:37<1:11:45,  3.78batch/s]Batch 3700/20010 Done, mean position loss: 32.548862960338596\n",
      "Training growing_up:  19%|██▏         | 3750/20010 [15:42<1:05:47,  4.12batch/s]Batch 3700/20010 Done, mean position loss: 34.3422278881073\n",
      "Training growing_up:  19%|██▏         | 3751/20010 [15:48<1:12:47,  3.72batch/s]Batch 3800/20010 Done, mean position loss: 35.097276496887204\n",
      "Training growing_up:  19%|██▎         | 3831/20010 [15:55<1:10:25,  3.83batch/s]Batch 3800/20010 Done, mean position loss: 31.38764639377594\n",
      "Training growing_up:  19%|██▎         | 3794/20010 [16:00<1:07:44,  3.99batch/s]Batch 3800/20010 Done, mean position loss: 32.469811840057375\n",
      "Training growing_up:  19%|██▎         | 3777/20010 [16:02<1:10:03,  3.86batch/s]Batch 3800/20010 Done, mean position loss: 32.71864698886871\n",
      "Training growing_up:  19%|██▎         | 3831/20010 [16:08<1:11:03,  3.79batch/s]Batch 3800/20010 Done, mean position loss: 32.340874080657954\n",
      "Training growing_up:  19%|██▎         | 3870/20010 [16:12<1:04:00,  4.20batch/s]Batch 3900/20010 Done, mean position loss: 32.59090948343277\n",
      "Training growing_up:  19%|██▎         | 3849/20010 [16:20<1:08:04,  3.96batch/s]Batch 3900/20010 Done, mean position loss: 33.226579802036284\n",
      "Training growing_up:  19%|██▎         | 3894/20010 [16:26<1:05:26,  4.10batch/s]Batch 3900/20010 Done, mean position loss: 30.863823747634886\n",
      "Training growing_up:  20%|██▎         | 3960/20010 [16:27<1:08:06,  3.93batch/s]Batch 3900/20010 Done, mean position loss: 33.99819159030914\n",
      "Training growing_up:  20%|██▍         | 3984/20010 [16:33<1:08:03,  3.92batch/s]Batch 3900/20010 Done, mean position loss: 31.478606038093567\n",
      "Training growing_up:  20%|██▍         | 3969/20010 [16:37<1:08:18,  3.91batch/s]Batch 4000/20010 Done, mean position loss: 31.47315915107727\n",
      "Training growing_up:  20%|██▍         | 3979/20010 [16:45<1:05:16,  4.09batch/s]Batch 4000/20010 Done, mean position loss: 33.27749126672745\n",
      "Training growing_up:  20%|██▍         | 3993/20010 [16:51<1:08:58,  3.87batch/s]Batch 4000/20010 Done, mean position loss: 31.05212005853653\n",
      "Training growing_up:  20%|██▍         | 3977/20010 [16:53<1:08:32,  3.90batch/s]Batch 4000/20010 Done, mean position loss: 32.531868941783905\n",
      "Training growing_up:  20%|██▍         | 4087/20010 [16:59<1:09:02,  3.84batch/s]Batch 4000/20010 Done, mean position loss: 34.28345398187638\n",
      "Training growing_up:  20%|██▍         | 4014/20010 [17:02<1:05:09,  4.09batch/s]Batch 4100/20010 Done, mean position loss: 31.45829034805298\n",
      "Training growing_up:  21%|██▍         | 4134/20010 [17:10<1:03:09,  4.19batch/s]Batch 4100/20010 Done, mean position loss: 30.370584123134613\n",
      "Training growing_up:  20%|██▍         | 4068/20010 [17:16<1:05:30,  4.06batch/s]Batch 4100/20010 Done, mean position loss: 30.510992703437807\n",
      "Training growing_up:  21%|██▍         | 4109/20010 [17:18<1:04:52,  4.09batch/s]Batch 4100/20010 Done, mean position loss: 30.377713038921357\n",
      "Training growing_up:  21%|██▍         | 4125/20010 [17:24<1:02:52,  4.21batch/s]Batch 4100/20010 Done, mean position loss: 32.54328392744064\n",
      "Training growing_up:  21%|██▍         | 4112/20010 [17:27<1:08:54,  3.85batch/s]Batch 4200/20010 Done, mean position loss: 31.99130751371384\n",
      "Training growing_up:  21%|██▌         | 4178/20010 [17:35<1:06:51,  3.95batch/s]Batch 4200/20010 Done, mean position loss: 31.593837571144107\n",
      "Training growing_up:  21%|██▌         | 4257/20010 [17:41<1:06:00,  3.98batch/s]Batch 4200/20010 Done, mean position loss: 31.131395006179808\n",
      "Training growing_up:  21%|██▌         | 4232/20010 [17:43<1:08:10,  3.86batch/s]Batch 4200/20010 Done, mean position loss: 32.06903873682022\n",
      "Training growing_up:  21%|██▌         | 4257/20010 [17:49<1:07:03,  3.92batch/s]Batch 4200/20010 Done, mean position loss: 31.236261081695556\n",
      "Training growing_up:  21%|██▌         | 4235/20010 [17:52<1:05:22,  4.02batch/s]Batch 4300/20010 Done, mean position loss: 30.494637308120726\n",
      "Training growing_up:  21%|██▌         | 4269/20010 [18:00<1:04:56,  4.04batch/s]Batch 4300/20010 Done, mean position loss: 34.96689896821975\n",
      "Training growing_up:  21%|██▌         | 4266/20010 [18:06<1:06:02,  3.97batch/s]Batch 4300/20010 Done, mean position loss: 33.62143804311752\n",
      "Training growing_up:  22%|██▌         | 4333/20010 [18:08<1:05:02,  4.02batch/s]Batch 4300/20010 Done, mean position loss: 33.781928017139435\n",
      "Training growing_up:  22%|██▌         | 4326/20010 [18:15<1:03:47,  4.10batch/s]Batch 4300/20010 Done, mean position loss: 33.886424360275264\n",
      "Training growing_up:  22%|██▌         | 4366/20010 [18:17<1:04:26,  4.05batch/s]Batch 4400/20010 Done, mean position loss: 30.735156769752503\n",
      "Training growing_up:  22%|██▋         | 4436/20010 [18:26<1:03:20,  4.10batch/s]Batch 4400/20010 Done, mean position loss: 32.37661204814911\n",
      "Training growing_up:  22%|██▋         | 4459/20010 [18:31<1:02:49,  4.13batch/s]Batch 4400/20010 Done, mean position loss: 32.524879796504976\n",
      "Training growing_up:  22%|██▋         | 4433/20010 [18:34<1:04:40,  4.01batch/s]Batch 4400/20010 Done, mean position loss: 30.960787374973297\n",
      "Training growing_up:  22%|██▋         | 4427/20010 [18:40<1:02:41,  4.14batch/s]Batch 4400/20010 Done, mean position loss: 31.010954809188846\n",
      "Training growing_up:  22%|██▋         | 4432/20010 [18:42<1:06:25,  3.91batch/s]Batch 4500/20010 Done, mean position loss: 29.995441570281983\n",
      "Training growing_up:  22%|██▋         | 4468/20010 [18:51<1:03:00,  4.11batch/s]Batch 4500/20010 Done, mean position loss: 33.06241023778915\n",
      "Training growing_up:  22%|██▋         | 4464/20010 [18:56<1:07:17,  3.85batch/s]Batch 4500/20010 Done, mean position loss: 30.7596639585495\n",
      "Training growing_up:  23%|██▋         | 4570/20010 [18:59<1:02:42,  4.10batch/s]Batch 4500/20010 Done, mean position loss: 29.5722351026535\n",
      "Training growing_up:  23%|██▋         | 4528/20010 [19:06<1:07:08,  3.84batch/s]Batch 4500/20010 Done, mean position loss: 34.18925147056579\n",
      "Training growing_up:  23%|██▋         | 4531/20010 [19:07<1:04:47,  3.98batch/s]Batch 4600/20010 Done, mean position loss: 30.452082622051236\n",
      "Training growing_up:  23%|██▋         | 4577/20010 [19:16<1:04:53,  3.96batch/s]Batch 4600/20010 Done, mean position loss: 36.369379122257236\n",
      "Training growing_up:  23%|██▋         | 4563/20010 [19:22<1:04:27,  3.99batch/s]Batch 4600/20010 Done, mean position loss: 31.637240567207336\n",
      "Training growing_up:  23%|██▊         | 4672/20010 [19:24<1:04:52,  3.94batch/s]Batch 4600/20010 Done, mean position loss: 29.364166293144226\n",
      "Training growing_up:  23%|██▊         | 4663/20010 [19:31<1:06:54,  3.82batch/s]Batch 4700/20010 Done, mean position loss: 31.054361186027528\n",
      "Training growing_up:  23%|██▊         | 4629/20010 [19:31<1:03:33,  4.03batch/s]Batch 4600/20010 Done, mean position loss: 33.08224473714829\n",
      "Training growing_up:  23%|██▊         | 4676/20010 [19:41<1:03:08,  4.05batch/s]Batch 4700/20010 Done, mean position loss: 29.467621009349823\n",
      "Training growing_up:  23%|██▊         | 4662/20010 [19:47<1:02:56,  4.06batch/s]Batch 4700/20010 Done, mean position loss: 31.9051850271225\n",
      "Training growing_up:  24%|██▊         | 4735/20010 [19:49<1:06:33,  3.83batch/s]Batch 4700/20010 Done, mean position loss: 31.079027080535887\n",
      "Training growing_up:  24%|██▊         | 4763/20010 [19:56<1:02:55,  4.04batch/s]Batch 4800/20010 Done, mean position loss: 30.146496505737304\n",
      "Training growing_up:  24%|██▊         | 4729/20010 [19:57<1:06:06,  3.85batch/s]Batch 4700/20010 Done, mean position loss: 32.38793051481247\n",
      "Training growing_up:  24%|██▊         | 4765/20010 [20:06<1:01:59,  4.10batch/s]Batch 4800/20010 Done, mean position loss: 33.132497031688686\n",
      "Training growing_up:  24%|██▊         | 4762/20010 [20:12<1:03:31,  4.00batch/s]Batch 4800/20010 Done, mean position loss: 31.41009114265442\n",
      "Training growing_up:  24%|██▉         | 4837/20010 [20:15<1:01:46,  4.09batch/s]Batch 4800/20010 Done, mean position loss: 30.83643077611923\n",
      "Training growing_up:  24%|██▉         | 4826/20010 [20:21<1:03:56,  3.96batch/s]Batch 4900/20010 Done, mean position loss: 30.334712395668028\n",
      "Training growing_up:  24%|██▉         | 4829/20010 [20:22<1:02:34,  4.04batch/s]Batch 4800/20010 Done, mean position loss: 31.4251194691658\n",
      "Training growing_up:  25%|██▉         | 4939/20010 [20:31<1:01:01,  4.12batch/s]Batch 4900/20010 Done, mean position loss: 31.63933755636215\n",
      "Training growing_up:  25%|██▉         | 4966/20010 [20:37<1:01:01,  4.11batch/s]Batch 4900/20010 Done, mean position loss: 33.26218142986298\n",
      "Training growing_up:  25%|██▉         | 4938/20010 [20:40<1:02:53,  3.99batch/s]Batch 4900/20010 Done, mean position loss: 33.24968735218048\n",
      "Training growing_up:  25%|██▉         | 4962/20010 [20:46<1:02:20,  4.02batch/s]Batch 5000/20010 Done, mean position loss: 29.570824024677275\n",
      "Training growing_up:  25%|██▉         | 4940/20010 [20:47<1:02:07,  4.04batch/s]Batch 4900/20010 Done, mean position loss: 32.64334566116333\n",
      "Training growing_up:  25%|██▉         | 4973/20010 [20:56<1:01:24,  4.08batch/s]Batch 5000/20010 Done, mean position loss: 30.22810520887375\n",
      "Training growing_up:  25%|██▉         | 4990/20010 [21:03<1:01:42,  4.06batch/s]Batch 5000/20010 Done, mean position loss: 35.86442237138748\n",
      "Training growing_up:  25%|███         | 5039/20010 [21:05<1:06:05,  3.78batch/s]Batch 5000/20010 Done, mean position loss: 29.059442958831788\n",
      "Training growing_up:  25%|██▉         | 4993/20010 [21:11<1:04:32,  3.88batch/s]Batch 5100/20010 Done, mean position loss: 28.49229900121689\n",
      "Training growing_up:  25%|███         | 5041/20010 [21:13<1:03:12,  3.95batch/s]Batch 5000/20010 Done, mean position loss: 31.39192051887512\n",
      "Training growing_up:  25%|███         | 5072/20010 [21:21<1:04:24,  3.87batch/s]Batch 5100/20010 Done, mean position loss: 31.052202785015105\n",
      "Training growing_up:  26%|███         | 5129/20010 [21:28<1:02:24,  3.97batch/s]Batch 5100/20010 Done, mean position loss: 29.839735717773436\n",
      "Training growing_up:  26%|███         | 5140/20010 [21:31<1:00:44,  4.08batch/s]Batch 5100/20010 Done, mean position loss: 30.396949236392974\n",
      "Training growing_up:  26%|███         | 5121/20010 [21:36<1:03:29,  3.91batch/s]Batch 5200/20010 Done, mean position loss: 32.72454010248184\n",
      "Training growing_up:  26%|███         | 5141/20010 [21:38<1:02:11,  3.98batch/s]Batch 5100/20010 Done, mean position loss: 30.650487291812897\n",
      "Training growing_up:  26%|███         | 5161/20010 [21:46<1:03:49,  3.88batch/s]Batch 5200/20010 Done, mean position loss: 32.16599054813385\n",
      "Training growing_up:  26%|███         | 5159/20010 [21:53<1:08:21,  3.62batch/s]Batch 5200/20010 Done, mean position loss: 31.381117045879364\n",
      "Training growing_up:  26%|███▏        | 5211/20010 [21:56<1:00:58,  4.05batch/s]Batch 5200/20010 Done, mean position loss: 28.727972066402437\n",
      "Training growing_up:  26%|███▏        | 5260/20010 [22:01<1:00:04,  4.09batch/s]Batch 5300/20010 Done, mean position loss: 30.2299086022377\n",
      "Training growing_up:  26%|███▏        | 5273/20010 [22:04<1:01:45,  3.98batch/s]Batch 5200/20010 Done, mean position loss: 31.93626174926758\n",
      "Training growing_up:  26%|███▏        | 5228/20010 [22:11<1:01:32,  4.00batch/s]Batch 5300/20010 Done, mean position loss: 30.049170980453493\n",
      "Training growing_up:  27%|███▏        | 5331/20010 [22:19<1:01:01,  4.01batch/s]Batch 5300/20010 Done, mean position loss: 29.19557507753372\n",
      "Training growing_up:  27%|███▋          | 5341/20010 [22:21<59:01,  4.14batch/s]Batch 5300/20010 Done, mean position loss: 29.505596487522126\n",
      "Training growing_up:  27%|███▏        | 5319/20010 [22:26<1:04:29,  3.80batch/s]Batch 5400/20010 Done, mean position loss: 31.38555538892746\n",
      "Training growing_up:  27%|███▊          | 5374/20010 [22:29<59:02,  4.13batch/s]Batch 5300/20010 Done, mean position loss: 29.04186562538147\n",
      "Training growing_up:  27%|███▏        | 5359/20010 [22:36<1:07:15,  3.63batch/s]Batch 5400/20010 Done, mean position loss: 29.6645636510849\n",
      "Training growing_up:  27%|███▎        | 5431/20010 [22:44<1:03:48,  3.81batch/s]Batch 5400/20010 Done, mean position loss: 31.477398223876953\n",
      "Training growing_up:  27%|███▏        | 5412/20010 [22:47<1:00:08,  4.05batch/s]Batch 5400/20010 Done, mean position loss: 30.045684089660647\n",
      "Training growing_up:  27%|███▊          | 5459/20010 [22:51<58:47,  4.12batch/s]Batch 5500/20010 Done, mean position loss: 28.08747533082962\n",
      "Training growing_up:  27%|███▊          | 5476/20010 [22:55<59:37,  4.06batch/s]Batch 5400/20010 Done, mean position loss: 29.126305656433104\n",
      "Training growing_up:  27%|███▎        | 5458/20010 [23:01<1:00:30,  4.01batch/s]Batch 5500/20010 Done, mean position loss: 30.543801574707032\n",
      "Training growing_up:  27%|███▎        | 5455/20010 [23:09<1:05:28,  3.70batch/s]Batch 5500/20010 Done, mean position loss: 29.01422248363495\n",
      "Training growing_up:  28%|███▎        | 5585/20010 [23:12<1:00:15,  3.99batch/s]Batch 5500/20010 Done, mean position loss: 30.616620416641236\n",
      "Training growing_up:  28%|███▎        | 5516/20010 [23:16<1:01:04,  3.96batch/s]Batch 5600/20010 Done, mean position loss: 29.12317305803299\n",
      "Training growing_up:  28%|███▉          | 5578/20010 [23:20<59:27,  4.05batch/s]Batch 5500/20010 Done, mean position loss: 30.285041961669922\n",
      "Training growing_up:  28%|███▎        | 5523/20010 [23:26<1:01:06,  3.95batch/s]Batch 5600/20010 Done, mean position loss: 28.33574683904648\n",
      "Training growing_up:  28%|███▍        | 5632/20010 [23:34<1:01:25,  3.90batch/s]Batch 5600/20010 Done, mean position loss: 29.78320389509201\n",
      "Training growing_up:  28%|███▉          | 5645/20010 [23:37<57:50,  4.14batch/s]Batch 5600/20010 Done, mean position loss: 29.239573879241945\n",
      "Training growing_up:  28%|███▉          | 5658/20010 [23:41<59:42,  4.01batch/s]Batch 5700/20010 Done, mean position loss: 30.53339200019836\n",
      "Training growing_up:  29%|████          | 5723/20010 [23:46<58:57,  4.04batch/s]Batch 5600/20010 Done, mean position loss: 31.090046250820162\n",
      "Training growing_up:  28%|███▍        | 5656/20010 [23:51<1:02:30,  3.83batch/s]Batch 5700/20010 Done, mean position loss: 28.310780024528505\n",
      "Training growing_up:  28%|███▉          | 5653/20010 [24:00<58:24,  4.10batch/s]Batch 5700/20010 Done, mean position loss: 30.728730809688567\n",
      "Training growing_up:  28%|███▍        | 5665/20010 [24:03<1:01:44,  3.87batch/s]Batch 5700/20010 Done, mean position loss: 30.339565036296847\n",
      "Training growing_up:  29%|███▍        | 5712/20010 [24:06<1:01:48,  3.86batch/s]Batch 5800/20010 Done, mean position loss: 28.772959697246552\n",
      "Training growing_up:  29%|████          | 5825/20010 [24:12<59:02,  4.00batch/s]Batch 5700/20010 Done, mean position loss: 30.02524206399918\n",
      "Training growing_up:  29%|████          | 5755/20010 [24:16<59:02,  4.02batch/s]Batch 5800/20010 Done, mean position loss: 30.261958358287814\n",
      "Training growing_up:  29%|████          | 5834/20010 [24:25<58:32,  4.04batch/s]Batch 5800/20010 Done, mean position loss: 28.65677758216858\n",
      "Training growing_up:  29%|████          | 5891/20010 [24:28<58:49,  4.00batch/s]Batch 5800/20010 Done, mean position loss: 30.23555414915085\n",
      "Training growing_up:  29%|████          | 5774/20010 [24:30<57:26,  4.13batch/s]Batch 5900/20010 Done, mean position loss: 29.0668258023262\n",
      "Training growing_up:  29%|████          | 5837/20010 [24:37<58:07,  4.06batch/s]Batch 5800/20010 Done, mean position loss: 28.767516798973084\n",
      "Training growing_up:  30%|████▏         | 5945/20010 [24:42<58:35,  4.00batch/s]Batch 5900/20010 Done, mean position loss: 29.737923576831818\n",
      "Training growing_up:  29%|███▌        | 5888/20010 [24:50<1:01:32,  3.82batch/s]Batch 5900/20010 Done, mean position loss: 28.744920661449434\n",
      "Training growing_up:  30%|████▏         | 5947/20010 [24:53<58:32,  4.00batch/s]Batch 5900/20010 Done, mean position loss: 29.172039678096773\n",
      "Training growing_up:  30%|████▏         | 5956/20010 [24:56<57:24,  4.08batch/s]Batch 6000/20010 Done, mean position loss: 29.59233726978302\n",
      "Training growing_up:  30%|███▌        | 5984/20010 [25:03<1:01:08,  3.82batch/s]Batch 5900/20010 Done, mean position loss: 28.183291263580323\n",
      "Training growing_up:  30%|████▏         | 6046/20010 [25:07<55:28,  4.20batch/s]Batch 6000/20010 Done, mean position loss: 28.903509998321532\n",
      "Training growing_up:  30%|████▏         | 5988/20010 [25:15<58:09,  4.02batch/s]Batch 6000/20010 Done, mean position loss: 30.561345422267916\n",
      "Training growing_up:  30%|████▏         | 6013/20010 [25:19<57:06,  4.09batch/s]Batch 6000/20010 Done, mean position loss: 28.243109271526336\n",
      "Training growing_up:  30%|███▌        | 6008/20010 [25:21<1:01:26,  3.80batch/s]Batch 6100/20010 Done, mean position loss: 28.33121967315674\n",
      "Training growing_up:  30%|████▏         | 6052/20010 [25:29<57:49,  4.02batch/s]Batch 6000/20010 Done, mean position loss: 29.311592309474946\n",
      "Training growing_up:  30%|████▏         | 6066/20010 [25:32<58:10,  4.00batch/s]Batch 6100/20010 Done, mean position loss: 27.036530668735505\n",
      "Training growing_up:  30%|███▋        | 6088/20010 [25:41<1:00:43,  3.82batch/s]Batch 6100/20010 Done, mean position loss: 29.71531236410141\n",
      "Training growing_up:  30%|████▏         | 6062/20010 [25:44<57:34,  4.04batch/s]Batch 6100/20010 Done, mean position loss: 28.12686306715012\n",
      "Training growing_up:  31%|████▎         | 6107/20010 [25:46<59:15,  3.91batch/s]Batch 6200/20010 Done, mean position loss: 28.019623308181764\n",
      "Training growing_up:  31%|████▎         | 6188/20010 [25:54<55:58,  4.12batch/s]Batch 6100/20010 Done, mean position loss: 31.563448522090912\n",
      "Training growing_up:  31%|███▋        | 6152/20010 [25:57<1:01:48,  3.74batch/s]Batch 6200/20010 Done, mean position loss: 27.599513661861423\n",
      "Training growing_up:  31%|████▎         | 6236/20010 [26:06<57:14,  4.01batch/s]Batch 6200/20010 Done, mean position loss: 27.922689037322996\n",
      "Training growing_up:  31%|████▍         | 6296/20010 [26:10<57:26,  3.98batch/s]Batch 6200/20010 Done, mean position loss: 28.292817397117616\n",
      "Training growing_up:  31%|████▎         | 6205/20010 [26:11<58:52,  3.91batch/s]Batch 6300/20010 Done, mean position loss: 28.26738268375397\n",
      "Training growing_up:  31%|████▎         | 6240/20010 [26:20<59:49,  3.84batch/s]Batch 6200/20010 Done, mean position loss: 28.050280339717865\n",
      "Training growing_up:  32%|████▍         | 6347/20010 [26:22<56:16,  4.05batch/s]Batch 6300/20010 Done, mean position loss: 28.52521148920059\n",
      "Training growing_up:  32%|███▊        | 6383/20010 [26:31<1:01:39,  3.68batch/s]Batch 6300/20010 Done, mean position loss: 30.310594418048858\n",
      "Training growing_up:  32%|████▍         | 6314/20010 [26:35<59:09,  3.86batch/s]Batch 6300/20010 Done, mean position loss: 31.93144155502319\n",
      "Training growing_up:  31%|███▊        | 6263/20010 [26:36<1:02:08,  3.69batch/s]Batch 6400/20010 Done, mean position loss: 30.18777554035187\n",
      "Training growing_up:  32%|████▍         | 6355/20010 [26:45<57:21,  3.97batch/s]Batch 6300/20010 Done, mean position loss: 27.609938235282897\n",
      "Training growing_up:  32%|████▍         | 6364/20010 [26:48<55:41,  4.08batch/s]Batch 6400/20010 Done, mean position loss: 26.925046367645265\n",
      "Training growing_up:  32%|████▌         | 6438/20010 [26:57<55:18,  4.09batch/s]Batch 6400/20010 Done, mean position loss: 28.04798290729523\n",
      "Training growing_up:  32%|████▌         | 6499/20010 [27:00<55:24,  4.06batch/s]Batch 6400/20010 Done, mean position loss: 28.335567178726198\n",
      "Training growing_up:  32%|████▌         | 6453/20010 [27:01<54:56,  4.11batch/s]Batch 6500/20010 Done, mean position loss: 28.772923705577853\n",
      "Training growing_up:  32%|████▌         | 6442/20010 [27:11<57:06,  3.96batch/s]Batch 6400/20010 Done, mean position loss: 27.74415702342987\n",
      "Training growing_up:  32%|███▉        | 6463/20010 [27:13<1:00:04,  3.76batch/s]Batch 6500/20010 Done, mean position loss: 27.937294118404388\n",
      "Training growing_up:  32%|███▉        | 6487/20010 [27:22<1:00:23,  3.73batch/s]Batch 6500/20010 Done, mean position loss: 27.536921334266662\n",
      "Training growing_up:  33%|████▌         | 6514/20010 [27:26<57:32,  3.91batch/s]Batch 6500/20010 Done, mean position loss: 27.541162533760073\n",
      "Training growing_up:  32%|███▉        | 6501/20010 [27:26<1:03:49,  3.53batch/s]Batch 6600/20010 Done, mean position loss: 27.90677662372589\n",
      "Training growing_up:  33%|████▌         | 6556/20010 [27:36<55:17,  4.06batch/s]Batch 6500/20010 Done, mean position loss: 28.594819519519806\n",
      "Training growing_up:  33%|████▌         | 6562/20010 [27:38<56:18,  3.98batch/s]Batch 6600/20010 Done, mean position loss: 26.993376173973083\n",
      "Training growing_up:  33%|████▌         | 6587/20010 [27:48<56:04,  3.99batch/s]Batch 6600/20010 Done, mean position loss: 26.949751288890837\n",
      "Training growing_up:  33%|███▉        | 6600/20010 [27:51<1:00:19,  3.71batch/s]Batch 6700/20010 Done, mean position loss: 28.814802412986754\n",
      "Training growing_up:  33%|████▋         | 6614/20010 [27:51<54:59,  4.06batch/s]Batch 6600/20010 Done, mean position loss: 27.707682259082794\n",
      "Training growing_up:  33%|████▋         | 6657/20010 [28:02<56:52,  3.91batch/s]Batch 6600/20010 Done, mean position loss: 29.452583503723147\n",
      "Training growing_up:  34%|████▋         | 6749/20010 [28:03<54:17,  4.07batch/s]Batch 6700/20010 Done, mean position loss: 27.27780523777008\n",
      "Training growing_up:  33%|████▋         | 6687/20010 [28:13<54:32,  4.07batch/s]Batch 6700/20010 Done, mean position loss: 28.486960813999175\n",
      "Training growing_up:  34%|████▋         | 6712/20010 [28:16<58:46,  3.77batch/s]Batch 6800/20010 Done, mean position loss: 27.811709225177765\n",
      "Training growing_up:  34%|████▋         | 6753/20010 [28:16<56:27,  3.91batch/s]Batch 6700/20010 Done, mean position loss: 29.518308408260346\n",
      "Training growing_up:  34%|████▋         | 6744/20010 [28:28<59:59,  3.69batch/s]Batch 6700/20010 Done, mean position loss: 28.246867041587826\n",
      "Training growing_up:  34%|████▋         | 6747/20010 [28:28<55:42,  3.97batch/s]Batch 6800/20010 Done, mean position loss: 27.69688334941864\n",
      "Training growing_up:  34%|████▊         | 6890/20010 [28:38<52:24,  4.17batch/s]Batch 6800/20010 Done, mean position loss: 27.985948612689974\n",
      "Training growing_up:  34%|████▊         | 6851/20010 [28:41<53:56,  4.07batch/s]Batch 6900/20010 Done, mean position loss: 29.19501175880432\n",
      "Training growing_up:  34%|████▊         | 6854/20010 [28:42<55:25,  3.96batch/s]Batch 6800/20010 Done, mean position loss: 27.46410115003586\n",
      "Training growing_up:  34%|████▊         | 6843/20010 [28:53<57:48,  3.80batch/s]Batch 6900/20010 Done, mean position loss: 26.896470541954038\n",
      "Training growing_up:  34%|████        | 6844/20010 [28:54<1:03:48,  3.44batch/s]Batch 6800/20010 Done, mean position loss: 29.896041402816774\n",
      "Training growing_up:  35%|████▉         | 6992/20010 [29:04<52:29,  4.13batch/s]Batch 6900/20010 Done, mean position loss: 27.235473301410675\n",
      "Training growing_up:  34%|████▊         | 6848/20010 [29:06<55:26,  3.96batch/s]Batch 7000/20010 Done, mean position loss: 27.056036431789398\n",
      "Training growing_up:  35%|████▊         | 6920/20010 [29:09<55:59,  3.90batch/s]Batch 6900/20010 Done, mean position loss: 28.911950886249542\n",
      "Training growing_up:  35%|████▉         | 7052/20010 [29:19<57:04,  3.78batch/s]Batch 7000/20010 Done, mean position loss: 28.535407493114473\n",
      "Training growing_up:  35%|████▉         | 7054/20010 [29:19<54:59,  3.93batch/s]Batch 6900/20010 Done, mean position loss: 29.392817430496216\n",
      "Training growing_up:  35%|████▉         | 7093/20010 [29:29<52:05,  4.13batch/s]Batch 7000/20010 Done, mean position loss: 27.77725244045258\n",
      "Training growing_up:  35%|████▉         | 7008/20010 [29:31<54:29,  3.98batch/s]Batch 7100/20010 Done, mean position loss: 27.450945992469787\n",
      "Training growing_up:  35%|████▊         | 6958/20010 [29:34<53:41,  4.05batch/s]Batch 7000/20010 Done, mean position loss: 28.712650954723358\n",
      "Training growing_up:  35%|████▉         | 7040/20010 [29:44<53:38,  4.03batch/s]Batch 7100/20010 Done, mean position loss: 28.50958361387253\n",
      "Training growing_up:  35%|████▎       | 7103/20010 [29:45<1:02:15,  3.45batch/s]Batch 7000/20010 Done, mean position loss: 28.637320017814634\n",
      "Training growing_up:  36%|█████         | 7191/20010 [29:54<51:25,  4.15batch/s]Batch 7100/20010 Done, mean position loss: 27.432536430358887\n",
      "Training growing_up:  36%|█████         | 7149/20010 [29:57<51:43,  4.14batch/s]Batch 7200/20010 Done, mean position loss: 26.539023525714875\n",
      "Training growing_up:  36%|█████         | 7210/20010 [29:59<56:29,  3.78batch/s]Batch 7100/20010 Done, mean position loss: 27.146206963062287\n",
      "Training growing_up:  36%|█████         | 7247/20010 [30:10<57:02,  3.73batch/s]Batch 7200/20010 Done, mean position loss: 26.441411526203154\n",
      "Training growing_up:  36%|█████         | 7253/20010 [30:11<59:08,  3.59batch/s]Batch 7100/20010 Done, mean position loss: 29.080337829589844\n",
      "Training growing_up:  36%|████▉         | 7137/20010 [30:21<56:11,  3.82batch/s]Batch 7200/20010 Done, mean position loss: 26.802232336997985\n",
      "Training growing_up:  36%|█████         | 7151/20010 [30:24<51:55,  4.13batch/s]Batch 7300/20010 Done, mean position loss: 27.857413551807404\n",
      "Training growing_up:  36%|█████         | 7214/20010 [30:25<59:12,  3.60batch/s]Batch 7200/20010 Done, mean position loss: 26.66652697563171\n",
      "Training growing_up:  36%|█████         | 7239/20010 [30:34<52:32,  4.05batch/s]Batch 7300/20010 Done, mean position loss: 26.214686875343325\n",
      "Training growing_up:  36%|█████         | 7248/20010 [30:37<52:48,  4.03batch/s]Batch 7200/20010 Done, mean position loss: 27.686994593143464\n",
      "Training growing_up:  36%|█████         | 7237/20010 [30:47<53:53,  3.95batch/s]Batch 7300/20010 Done, mean position loss: 27.10080816030502\n",
      "Training growing_up:  37%|█████▏        | 7358/20010 [30:50<51:38,  4.08batch/s]Batch 7300/20010 Done, mean position loss: 27.01363041162491\n",
      "Training growing_up:  36%|█████         | 7255/20010 [30:51<54:02,  3.93batch/s]Batch 7400/20010 Done, mean position loss: 27.288330233097078\n",
      "Training growing_up:  37%|█████▏        | 7343/20010 [31:01<52:27,  4.02batch/s]Batch 7400/20010 Done, mean position loss: 28.520225615501403\n",
      "Training growing_up:  37%|█████▏        | 7365/20010 [31:03<51:48,  4.07batch/s]Batch 7300/20010 Done, mean position loss: 28.36180597782135\n",
      "Training growing_up:  37%|█████▏        | 7440/20010 [31:12<51:22,  4.08batch/s]Batch 7400/20010 Done, mean position loss: 27.544535872936248\n",
      "Training growing_up:  37%|█████▏        | 7499/20010 [31:15<49:42,  4.19batch/s]Batch 7400/20010 Done, mean position loss: 29.37102018594742\n",
      "Training growing_up:  37%|█████▏        | 7457/20010 [31:16<50:50,  4.12batch/s]Batch 7500/20010 Done, mean position loss: 26.984835200309753\n",
      "Training growing_up:  37%|█████▏        | 7445/20010 [31:27<54:02,  3.88batch/s]Batch 7500/20010 Done, mean position loss: 27.015072445869446\n",
      "Training growing_up:  37%|█████▏        | 7452/20010 [31:29<55:57,  3.74batch/s]Batch 7400/20010 Done, mean position loss: 28.79906375408173\n",
      "Training growing_up:  38%|█████▎        | 7587/20010 [31:38<53:01,  3.90batch/s]Batch 7500/20010 Done, mean position loss: 26.889714469909666\n",
      "Training growing_up:  38%|█████▎        | 7512/20010 [31:41<55:02,  3.78batch/s]Batch 7500/20010 Done, mean position loss: 27.37031875371933\n",
      "Training growing_up:  38%|█████▎        | 7557/20010 [31:41<51:30,  4.03batch/s]Batch 7600/20010 Done, mean position loss: 27.788155553340914\n",
      "Training growing_up:  37%|█████▏        | 7492/20010 [31:52<51:14,  4.07batch/s]Batch 7600/20010 Done, mean position loss: 27.58596882581711\n",
      "Training growing_up:  38%|█████▎        | 7608/20010 [31:54<54:18,  3.81batch/s]Batch 7500/20010 Done, mean position loss: 27.617200057506558\n",
      "Training growing_up:  38%|█████▎        | 7641/20010 [32:03<54:41,  3.77batch/s]Batch 7600/20010 Done, mean position loss: 27.023224081993103\n",
      "Training growing_up:  38%|█████▎        | 7613/20010 [32:06<53:01,  3.90batch/s]Batch 7600/20010 Done, mean position loss: 26.997148311138154\n",
      "Batch 7700/20010 Done, mean position loss: 27.90177371740341\n",
      "Training growing_up:  39%|█████▍        | 7750/20010 [32:20<49:06,  4.16batch/s]Batch 7700/20010 Done, mean position loss: 28.546495442390444\n",
      "Training growing_up:  38%|█████▎        | 7667/20010 [32:20<49:34,  4.15batch/s]Batch 7600/20010 Done, mean position loss: 27.29430992603302\n",
      "Training growing_up:  39%|█████▍        | 7786/20010 [32:29<53:20,  3.82batch/s]Batch 7700/20010 Done, mean position loss: 26.792567229270936\n",
      "Training growing_up:  39%|█████▍        | 7714/20010 [32:32<51:39,  3.97batch/s]Batch 7800/20010 Done, mean position loss: 27.4659357380867\n",
      "Training growing_up:  38%|█████▎        | 7647/20010 [32:33<52:27,  3.93batch/s]Batch 7700/20010 Done, mean position loss: 26.64885107278824\n",
      "Training growing_up:  39%|█████▍        | 7749/20010 [32:46<50:53,  4.02batch/s]Batch 7800/20010 Done, mean position loss: 27.293595621585848\n",
      "Training growing_up:  39%|█████▍        | 7751/20010 [32:46<49:54,  4.09batch/s]Batch 7700/20010 Done, mean position loss: 27.801580028533934\n",
      "Training growing_up:  39%|█████▍        | 7730/20010 [32:54<52:01,  3.93batch/s]Batch 7800/20010 Done, mean position loss: 27.05195987224579\n",
      "Training growing_up:  39%|█████▍        | 7799/20010 [32:59<48:40,  4.18batch/s]Batch 7900/20010 Done, mean position loss: 28.315725488662718\n",
      "Training growing_up:  39%|█████▍        | 7849/20010 [32:59<49:33,  4.09batch/s]Batch 7800/20010 Done, mean position loss: 27.213198704719545\n",
      "Training growing_up:  39%|█████▍        | 7849/20010 [33:12<49:45,  4.07batch/s]Batch 7900/20010 Done, mean position loss: 26.85158835887909\n",
      "Training growing_up:  39%|█████▌        | 7901/20010 [33:12<58:07,  3.47batch/s]Batch 7800/20010 Done, mean position loss: 27.847934811115266\n",
      "Training growing_up:  40%|█████▌        | 7930/20010 [33:20<54:13,  3.71batch/s]Batch 7900/20010 Done, mean position loss: 26.599583504199984\n",
      "Training growing_up:  40%|█████▌        | 7914/20010 [33:24<54:02,  3.73batch/s]Batch 8000/20010 Done, mean position loss: 28.088993735313416\n",
      "Training growing_up:  40%|█████▌        | 7948/20010 [33:25<49:54,  4.03batch/s]Batch 7900/20010 Done, mean position loss: 28.21999519109726\n",
      "Training growing_up:  40%|█████▋        | 8057/20010 [33:38<49:03,  4.06batch/s]Batch 8000/20010 Done, mean position loss: 26.59218766450882\n",
      "Training growing_up:  40%|█████▌        | 8001/20010 [33:39<57:02,  3.51batch/s]Batch 7900/20010 Done, mean position loss: 27.29311293363571\n",
      "Training growing_up:  40%|█████▌        | 7929/20010 [33:46<51:46,  3.89batch/s]Batch 8000/20010 Done, mean position loss: 27.02101146697998\n",
      "Training growing_up:  40%|█████▌        | 7941/20010 [33:49<50:26,  3.99batch/s]Batch 8100/20010 Done, mean position loss: 27.414322288036345\n",
      "Training growing_up:  40%|█████▌        | 8016/20010 [33:51<54:34,  3.66batch/s]Batch 8000/20010 Done, mean position loss: 27.54045117139816\n",
      "Training growing_up:  40%|█████▋        | 8053/20010 [34:05<51:51,  3.84batch/s]Batch 8100/20010 Done, mean position loss: 25.87739090681076\n",
      "Batch 8000/20010 Done, mean position loss: 27.068180277347565\n",
      "Training growing_up:  40%|█████▌        | 8029/20010 [34:13<55:35,  3.59batch/s]Batch 8100/20010 Done, mean position loss: 28.614372727870943\n",
      "Training growing_up:  40%|█████▋        | 8093/20010 [34:14<47:48,  4.15batch/s]Batch 8200/20010 Done, mean position loss: 26.62318170785904\n",
      "Training growing_up:  41%|█████▋        | 8114/20010 [34:17<55:27,  3.58batch/s]Batch 8100/20010 Done, mean position loss: 26.40605375289917\n",
      "Training growing_up:  41%|████▉       | 8161/20010 [34:30<1:00:54,  3.24batch/s]Batch 8200/20010 Done, mean position loss: 27.15874081134796\n",
      "Training growing_up:  41%|█████▋        | 8204/20010 [34:31<59:18,  3.32batch/s]Batch 8100/20010 Done, mean position loss: 26.344923069477083\n",
      "Training growing_up:  41%|█████▊        | 8295/20010 [34:42<53:54,  3.62batch/s]Batch 8200/20010 Done, mean position loss: 27.590937223434448\n",
      "Training growing_up:  41%|█████▊        | 8247/20010 [34:43<48:45,  4.02batch/s]Batch 8300/20010 Done, mean position loss: 26.64377902030945\n",
      "Training growing_up:  41%|█████▋        | 8150/20010 [34:45<49:02,  4.03batch/s]Batch 8200/20010 Done, mean position loss: 27.01905885696411\n",
      "Training growing_up:  42%|█████▊        | 8353/20010 [34:57<50:11,  3.87batch/s]Batch 8300/20010 Done, mean position loss: 26.565325169563295\n",
      "Training growing_up:  41%|█████▊        | 8304/20010 [34:58<58:10,  3.35batch/s]Batch 8200/20010 Done, mean position loss: 26.968269891738892\n",
      "Training growing_up:  41%|█████▊        | 8300/20010 [35:08<48:03,  4.06batch/s]Batch 8400/20010 Done, mean position loss: 26.632919733524325\n",
      "Training growing_up:  42%|█████▉        | 8401/20010 [35:09<55:48,  3.47batch/s]Batch 8300/20010 Done, mean position loss: 26.21495263814926\n",
      "Training growing_up:  41%|█████▊        | 8252/20010 [35:11<53:05,  3.69batch/s]Batch 8300/20010 Done, mean position loss: 26.702459063529968\n",
      "Training growing_up:  42%|█████▊        | 8342/20010 [35:22<48:01,  4.05batch/s]Batch 8400/20010 Done, mean position loss: 26.673433830738066\n",
      "Training growing_up:  42%|█████▊        | 8349/20010 [35:24<47:47,  4.07batch/s]Batch 8300/20010 Done, mean position loss: 27.365453028678893\n",
      "Training growing_up:  42%|█████▉        | 8443/20010 [35:34<50:34,  3.81batch/s]Batch 8500/20010 Done, mean position loss: 28.548050334453585\n",
      "Training growing_up:  42%|█████▊        | 8391/20010 [35:34<48:07,  4.02batch/s]Batch 8400/20010 Done, mean position loss: 26.921213357448575\n",
      "Training growing_up:  42%|█████▉        | 8410/20010 [35:37<48:02,  4.02batch/s]Batch 8400/20010 Done, mean position loss: 27.637663288116457\n",
      "Training growing_up:  42%|█████▉        | 8444/20010 [35:48<51:14,  3.76batch/s]Batch 8500/20010 Done, mean position loss: 26.557017645835877\n",
      "Training growing_up:  43%|█████▉        | 8506/20010 [35:50<49:31,  3.87batch/s]Batch 8400/20010 Done, mean position loss: 25.861390426158906\n",
      "Training growing_up:  42%|█████▉        | 8435/20010 [35:59<50:33,  3.82batch/s]Batch 8600/20010 Done, mean position loss: 26.667800529003145\n",
      "Training growing_up:  42%|█████▉        | 8436/20010 [36:00<54:25,  3.54batch/s]Batch 8500/20010 Done, mean position loss: 26.019900081157687\n",
      "Training growing_up:  43%|█████▉        | 8557/20010 [36:03<47:11,  4.04batch/s]Batch 8500/20010 Done, mean position loss: 26.038567709922788\n",
      "Training growing_up:  43%|█████▉        | 8541/20010 [36:14<47:36,  4.02batch/s]Batch 8600/20010 Done, mean position loss: 27.02754093885422\n",
      "Training growing_up:  43%|█████▉        | 8561/20010 [36:16<52:01,  3.67batch/s]Batch 8500/20010 Done, mean position loss: 27.355521304607393\n",
      "Training growing_up:  43%|█████▉        | 8533/20010 [36:25<50:25,  3.79batch/s]Batch 8700/20010 Done, mean position loss: 27.836584250926972\n",
      "Training growing_up:  43%|█████▉        | 8536/20010 [36:26<56:10,  3.40batch/s]Batch 8600/20010 Done, mean position loss: 26.451339528560638\n",
      "Training growing_up:  44%|██████        | 8714/20010 [36:29<46:49,  4.02batch/s]Batch 8600/20010 Done, mean position loss: 26.011846837997435\n",
      "Training growing_up:  43%|██████        | 8640/20010 [36:39<47:07,  4.02batch/s]Batch 8700/20010 Done, mean position loss: 26.71172650575638\n",
      "Training growing_up:  44%|██████▏       | 8770/20010 [36:43<49:17,  3.80batch/s]Batch 8600/20010 Done, mean position loss: 26.734723408222198\n",
      "Training growing_up:  43%|██████        | 8627/20010 [36:51<53:26,  3.55batch/s]Batch 8800/20010 Done, mean position loss: 26.470658671855926\n",
      "Training growing_up:  43%|██████        | 8642/20010 [36:54<46:19,  4.09batch/s]Batch 8700/20010 Done, mean position loss: 26.533931980133055\n",
      "Training growing_up:  43%|█████▏      | 8702/20010 [36:55<1:01:48,  3.05batch/s]Batch 8700/20010 Done, mean position loss: 26.145296964645382\n",
      "Training growing_up:  44%|██████        | 8744/20010 [37:06<50:36,  3.71batch/s]Batch 8800/20010 Done, mean position loss: 26.521485896110534\n",
      "Training growing_up:  44%|██████▏       | 8759/20010 [37:09<46:01,  4.07batch/s]Batch 8700/20010 Done, mean position loss: 26.872091748714446\n",
      "Training growing_up:  44%|██████▏       | 8784/20010 [37:16<45:55,  4.07batch/s]Batch 8900/20010 Done, mean position loss: 27.19167200088501\n",
      "Training growing_up:  45%|██████▏       | 8917/20010 [37:20<45:09,  4.09batch/s]Batch 8800/20010 Done, mean position loss: 26.63115786075592\n",
      "Training growing_up:  44%|██████▏       | 8859/20010 [37:20<45:16,  4.10batch/s]Batch 8800/20010 Done, mean position loss: 27.328985052108763\n",
      "Training growing_up:  44%|██████▏       | 8785/20010 [37:31<46:22,  4.03batch/s]Batch 8900/20010 Done, mean position loss: 25.943573198318482\n",
      "Training growing_up:  45%|██████▏       | 8915/20010 [37:35<49:12,  3.76batch/s]Batch 8800/20010 Done, mean position loss: 27.253974008560178\n",
      "Training growing_up:  45%|██████▎       | 8936/20010 [37:41<53:09,  3.47batch/s]Batch 9000/20010 Done, mean position loss: 26.08203379392624\n",
      "Training growing_up:  45%|██████▎       | 8953/20010 [37:45<51:33,  3.57batch/s]Batch 8900/20010 Done, mean position loss: 25.798109731674195\n",
      "Training growing_up:  44%|██████▏       | 8902/20010 [37:46<59:17,  3.12batch/s]Batch 8900/20010 Done, mean position loss: 27.682539536952973\n",
      "Training growing_up:  45%|██████▎       | 8946/20010 [37:57<46:29,  3.97batch/s]Batch 9000/20010 Done, mean position loss: 25.288378803730012\n",
      "Training growing_up:  45%|██████▎       | 9012/20010 [38:01<51:20,  3.57batch/s]Batch 8900/20010 Done, mean position loss: 25.7836074924469\n",
      "Training growing_up:  45%|██████▎       | 8980/20010 [38:07<52:10,  3.52batch/s]Batch 9100/20010 Done, mean position loss: 27.098271360397337\n",
      "Training growing_up:  45%|██████▎       | 9053/20010 [38:12<53:03,  3.44batch/s]Batch 9000/20010 Done, mean position loss: 26.137753674983976\n",
      "Training growing_up:  45%|█████▍      | 9003/20010 [38:13<1:00:27,  3.03batch/s]Batch 9000/20010 Done, mean position loss: 27.94757196903229\n",
      "Training growing_up:  45%|██████▎       | 9045/20010 [38:24<47:21,  3.86batch/s]Batch 9100/20010 Done, mean position loss: 26.50830619573593\n",
      "Training growing_up:  46%|██████▍       | 9178/20010 [38:28<46:15,  3.90batch/s]Batch 9000/20010 Done, mean position loss: 26.677966878414153\n",
      "Training growing_up:  46%|██████▍       | 9136/20010 [38:33<47:17,  3.83batch/s]Batch 9200/20010 Done, mean position loss: 26.865918509960174\n",
      "Training growing_up:  45%|██████▎       | 9098/20010 [38:38<44:50,  4.06batch/s]Batch 9100/20010 Done, mean position loss: 26.510277376174926\n",
      "Training growing_up:  46%|██████▍       | 9159/20010 [38:39<43:31,  4.15batch/s]Batch 9100/20010 Done, mean position loss: 27.04818927526474\n",
      "Training growing_up:  46%|██████▍       | 9138/20010 [38:49<45:37,  3.97batch/s]Batch 9200/20010 Done, mean position loss: 25.847109038829807\n",
      "Training growing_up:  46%|██████▍       | 9219/20010 [38:54<47:24,  3.79batch/s]Batch 9100/20010 Done, mean position loss: 26.902247519493102\n",
      "Training growing_up:  46%|██████▍       | 9124/20010 [39:00<45:16,  4.01batch/s]Batch 9300/20010 Done, mean position loss: 25.681574473381044\n",
      "Training growing_up:  47%|██████▌       | 9313/20010 [39:04<47:54,  3.72batch/s]Batch 9200/20010 Done, mean position loss: 26.233343579769134\n",
      "Training growing_up:  46%|██████▍       | 9205/20010 [39:05<51:30,  3.50batch/s]Batch 9200/20010 Done, mean position loss: 27.251633505821225\n",
      "Training growing_up:  46%|██████▍       | 9237/20010 [39:15<48:07,  3.73batch/s]Batch 9300/20010 Done, mean position loss: 25.843647582530977\n",
      "Training growing_up:  46%|██████▍       | 9261/20010 [39:20<47:19,  3.78batch/s]Batch 9200/20010 Done, mean position loss: 25.747367672920227\n",
      "Training growing_up:  47%|██████▌       | 9344/20010 [39:26<46:30,  3.82batch/s]Batch 9400/20010 Done, mean position loss: 25.85940158843994\n",
      "Training growing_up:  46%|██████▌       | 9297/20010 [39:30<44:18,  4.03batch/s]Batch 9300/20010 Done, mean position loss: 26.21088505744934\n",
      "Training growing_up:  46%|██████▍       | 9240/20010 [39:31<44:58,  3.99batch/s]Batch 9300/20010 Done, mean position loss: 26.949975736141205\n",
      "Training growing_up:  47%|██████▌       | 9338/20010 [39:40<49:07,  3.62batch/s]Batch 9400/20010 Done, mean position loss: 26.23702042579651\n",
      "Training growing_up:  47%|██████▌       | 9421/20010 [39:46<48:23,  3.65batch/s]Batch 9300/20010 Done, mean position loss: 26.095961463451385\n",
      "Training growing_up:  47%|██████▌       | 9381/20010 [39:52<44:57,  3.94batch/s]Batch 9500/20010 Done, mean position loss: 25.903778123855588\n",
      "Training growing_up:  47%|██████▌       | 9462/20010 [39:56<45:52,  3.83batch/s]Batch 9400/20010 Done, mean position loss: 25.85351309776306\n",
      "Batch 9400/20010 Done, mean position loss: 26.151456000804902\n",
      "Training growing_up:  47%|██████▌       | 9379/20010 [40:06<45:26,  3.90batch/s]Batch 9500/20010 Done, mean position loss: 26.056181161403657\n",
      "Training growing_up:  47%|██████▌       | 9457/20010 [40:12<43:58,  4.00batch/s]Batch 9400/20010 Done, mean position loss: 26.58202061653137\n",
      "Training growing_up:  47%|██████▌       | 9420/20010 [40:17<48:59,  3.60batch/s]Batch 9600/20010 Done, mean position loss: 26.67471706867218\n",
      "Training growing_up:  47%|██████▌       | 9442/20010 [40:23<43:35,  4.04batch/s]Batch 9500/20010 Done, mean position loss: 26.27459825515747\n",
      "Training growing_up:  47%|██████▌       | 9445/20010 [40:23<45:32,  3.87batch/s]Batch 9500/20010 Done, mean position loss: 26.59429963350296\n",
      "Training growing_up:  48%|██████▋       | 9533/20010 [40:32<42:10,  4.14batch/s]Batch 9600/20010 Done, mean position loss: 25.80596970319748\n",
      "Training growing_up:  48%|██████▋       | 9555/20010 [40:38<43:04,  4.04batch/s]Batch 9500/20010 Done, mean position loss: 26.009824588298798\n",
      "Training growing_up:  48%|██████▋       | 9578/20010 [40:43<45:11,  3.85batch/s]Batch 9700/20010 Done, mean position loss: 25.453081519603728\n",
      "Training growing_up:  49%|██████▊       | 9720/20010 [40:49<48:21,  3.55batch/s]Batch 9600/20010 Done, mean position loss: 25.380115208625796\n",
      "Training growing_up:  48%|██████▋       | 9544/20010 [40:49<46:54,  3.72batch/s]Batch 9600/20010 Done, mean position loss: 26.40189409017563\n",
      "Training growing_up:  48%|██████▋       | 9632/20010 [40:57<43:01,  4.02batch/s]Batch 9700/20010 Done, mean position loss: 26.946885643005373\n",
      "Training growing_up:  48%|██████▊       | 9657/20010 [41:04<42:43,  4.04batch/s]Batch 9600/20010 Done, mean position loss: 26.749804341793062\n",
      "Training growing_up:  48%|██████▊       | 9681/20010 [41:10<43:13,  3.98batch/s]Batch 9800/20010 Done, mean position loss: 26.1751678109169\n",
      "Training growing_up:  49%|██████▊       | 9818/20010 [41:14<44:23,  3.83batch/s]Batch 9700/20010 Done, mean position loss: 26.566431796550752\n",
      "Training growing_up:  48%|██████▋       | 9641/20010 [41:15<43:23,  3.98batch/s]Batch 9700/20010 Done, mean position loss: 26.13625846147537\n",
      "Training growing_up:  49%|██████▊       | 9732/20010 [41:23<41:59,  4.08batch/s]Batch 9800/20010 Done, mean position loss: 26.334484629631042\n",
      "Training growing_up:  49%|██████▊       | 9761/20010 [41:30<44:37,  3.83batch/s]Batch 9700/20010 Done, mean position loss: 25.360243740081785\n",
      "Training growing_up:  49%|██████▊       | 9720/20010 [41:35<45:30,  3.77batch/s]Batch 9900/20010 Done, mean position loss: 25.25822561264038\n",
      "Training growing_up:  49%|██████▉       | 9866/20010 [41:40<41:13,  4.10batch/s]Batch 9800/20010 Done, mean position loss: 25.85827848672867\n",
      "Training growing_up:  49%|██████▊       | 9739/20010 [41:40<43:03,  3.98batch/s]Batch 9800/20010 Done, mean position loss: 25.300541362762452\n",
      "Training growing_up:  49%|██████▉       | 9834/20010 [41:49<42:12,  4.02batch/s]Batch 9900/20010 Done, mean position loss: 25.337253980636596\n",
      "Training growing_up:  50%|██████▉       | 9927/20010 [41:56<45:13,  3.72batch/s]Batch 9800/20010 Done, mean position loss: 27.526260578632353\n",
      "Training growing_up:  50%|██████▉       | 9953/20010 [42:02<43:34,  3.85batch/s]Batch 10000/20010 Done, mean position loss: 26.29831364631653\n",
      "Training growing_up:  49%|██████▉       | 9837/20010 [42:05<44:20,  3.82batch/s]Batch 9900/20010 Done, mean position loss: 25.641624178886417\n",
      "Training growing_up:  49%|██████▉       | 9902/20010 [42:06<53:03,  3.18batch/s]Batch 9900/20010 Done, mean position loss: 26.672220299243925\n",
      "Training growing_up:  50%|██████▉       | 9933/20010 [42:14<41:17,  4.07batch/s]Batch 10000/20010 Done, mean position loss: 25.074968667030333\n",
      "Training growing_up:  50%|██████▉       | 9963/20010 [42:21<42:50,  3.91batch/s]Batch 9900/20010 Done, mean position loss: 26.113021178245543\n",
      "Training growing_up:  50%|██████▉       | 9987/20010 [42:27<42:42,  3.91batch/s]Batch 10100/20010 Done, mean position loss: 26.098062772750854\n",
      "Training growing_up:  51%|██████▌      | 10112/20010 [42:31<46:47,  3.53batch/s]Batch 10000/20010 Done, mean position loss: 26.0679820227623\n",
      "Training growing_up:  50%|██████▌      | 10066/20010 [42:32<41:01,  4.04batch/s]Batch 10000/20010 Done, mean position loss: 27.585733706951142\n",
      "Training growing_up:  51%|██████▌      | 10148/20010 [42:40<40:46,  4.03batch/s]Batch 10100/20010 Done, mean position loss: 24.947102870941166\n",
      "Training growing_up:  50%|██████▌      | 10060/20010 [42:47<41:36,  3.98batch/s]Batch 10000/20010 Done, mean position loss: 25.704674258232117\n",
      "Training growing_up:  51%|██████▌      | 10147/20010 [42:53<42:22,  3.88batch/s]Batch 10200/20010 Done, mean position loss: 26.138296852111818\n",
      "Training growing_up:  51%|██████▌      | 10163/20010 [42:57<41:03,  4.00batch/s]Batch 10100/20010 Done, mean position loss: 25.568154010772705\n",
      "Training growing_up:  51%|██████▌      | 10167/20010 [42:58<39:52,  4.11batch/s]Batch 10100/20010 Done, mean position loss: 25.522323632240294\n",
      "Training growing_up:  51%|██████▌      | 10134/20010 [43:07<45:04,  3.65batch/s]Batch 10200/20010 Done, mean position loss: 26.402326149940492\n",
      "Training growing_up:  51%|██████▌      | 10156/20010 [43:13<46:57,  3.50batch/s]Batch 10100/20010 Done, mean position loss: 26.595191543102267\n",
      "Training growing_up:  51%|██████▋      | 10242/20010 [43:19<44:37,  3.65batch/s]Batch 10300/20010 Done, mean position loss: 25.207065606117247\n",
      "Training growing_up:  52%|██████▋      | 10322/20010 [43:25<44:42,  3.61batch/s]Batch 10200/20010 Done, mean position loss: 25.45143406152725\n",
      "Training growing_up:  51%|██████▋      | 10202/20010 [43:26<52:26,  3.12batch/s]Batch 10200/20010 Done, mean position loss: 26.301922624111175\n",
      "Training growing_up:  52%|██████▋      | 10357/20010 [43:34<38:17,  4.20batch/s]Batch 10300/20010 Done, mean position loss: 25.234187490940094\n",
      "Training growing_up:  51%|██████▋      | 10256/20010 [43:41<40:31,  4.01batch/s]Batch 10200/20010 Done, mean position loss: 26.561845545768737\n",
      "Training growing_up:  51%|██████▋      | 10271/20010 [43:45<41:36,  3.90batch/s]Batch 10400/20010 Done, mean position loss: 26.098939056396485\n",
      "Training growing_up:  51%|██████▋      | 10293/20010 [43:51<39:05,  4.14batch/s]Batch 10300/20010 Done, mean position loss: 25.685028581619264\n",
      "Training growing_up:  52%|██████▊      | 10428/20010 [43:53<41:46,  3.82batch/s]Batch 10300/20010 Done, mean position loss: 25.267484333515167\n",
      "Training growing_up:  52%|██████▋      | 10332/20010 [44:00<44:17,  3.64batch/s]Batch 10400/20010 Done, mean position loss: 24.636550433635712\n",
      "Training growing_up:  52%|██████▊      | 10428/20010 [44:07<42:08,  3.79batch/s]Batch 10300/20010 Done, mean position loss: 24.588660500049592\n",
      "Training growing_up:  52%|██████▋      | 10365/20010 [44:11<44:25,  3.62batch/s]Batch 10500/20010 Done, mean position loss: 25.63289169549942\n",
      "Training growing_up:  52%|██████▊      | 10474/20010 [44:19<39:23,  4.03batch/s]Batch 10400/20010 Done, mean position loss: 26.185145106315613\n",
      "Training growing_up:  53%|██████▊      | 10535/20010 [44:21<42:34,  3.71batch/s]Batch 10400/20010 Done, mean position loss: 25.299948799610135\n",
      "Training growing_up:  52%|██████▊      | 10425/20010 [44:26<39:21,  4.06batch/s]Batch 10500/20010 Done, mean position loss: 25.58978976011276\n",
      "Training growing_up:  52%|██████▊      | 10455/20010 [44:33<40:26,  3.94batch/s]Batch 10400/20010 Done, mean position loss: 26.062880856990816\n",
      "Training growing_up:  52%|██████▊      | 10470/20010 [44:37<41:22,  3.84batch/s]Batch 10600/20010 Done, mean position loss: 26.188672869205476\n",
      "Training growing_up:  53%|██████▉      | 10630/20010 [44:45<38:55,  4.02batch/s]Batch 10500/20010 Done, mean position loss: 25.81799861431122\n",
      "Training growing_up:  52%|██████▊      | 10451/20010 [44:46<38:54,  4.09batch/s]Batch 10500/20010 Done, mean position loss: 25.69612763404846\n",
      "Training growing_up:  53%|██████▉      | 10655/20010 [44:51<37:39,  4.14batch/s]Batch 10600/20010 Done, mean position loss: 24.451876494884488\n",
      "Training growing_up:  53%|██████▊      | 10555/20010 [44:59<39:43,  3.97batch/s]Batch 10500/20010 Done, mean position loss: 25.11863673686981\n",
      "Training growing_up:  53%|██████▉      | 10644/20010 [45:02<41:16,  3.78batch/s]Batch 10700/20010 Done, mean position loss: 25.309855666160587\n",
      "Training growing_up:  53%|██████▉      | 10591/20010 [45:11<38:45,  4.05batch/s]Batch 10600/20010 Done, mean position loss: 24.850586855411528\n",
      "Training growing_up:  53%|██████▉      | 10687/20010 [45:13<39:51,  3.90batch/s]Batch 10600/20010 Done, mean position loss: 25.58397825717926\n",
      "Training growing_up:  53%|██████▊      | 10566/20010 [45:17<39:07,  4.02batch/s]Batch 10700/20010 Done, mean position loss: 25.32503475189209\n",
      "Training growing_up:  53%|██████▉      | 10658/20010 [45:25<38:22,  4.06batch/s]Batch 10600/20010 Done, mean position loss: 25.47683772325516\n",
      "Training growing_up:  53%|██████▉      | 10656/20010 [45:28<38:58,  4.00batch/s]Batch 10800/20010 Done, mean position loss: 25.68417882680893\n",
      "Training growing_up:  53%|██████▉      | 10642/20010 [45:36<38:10,  4.09batch/s]Batch 10700/20010 Done, mean position loss: 25.845389165878295\n",
      "Training growing_up:  54%|███████      | 10789/20010 [45:39<38:25,  4.00batch/s]Batch 10700/20010 Done, mean position loss: 25.487746465206143\n",
      "Training growing_up:  53%|██████▉      | 10664/20010 [45:42<38:57,  4.00batch/s]Batch 10800/20010 Done, mean position loss: 25.73949886083603\n",
      "Training growing_up:  54%|██████▉      | 10759/20010 [45:51<38:08,  4.04batch/s]Batch 10700/20010 Done, mean position loss: 25.401816971302033\n",
      "Training growing_up:  54%|██████▉      | 10760/20010 [45:54<37:02,  4.16batch/s]Batch 10900/20010 Done, mean position loss: 25.2116655421257\n",
      "Training growing_up:  55%|███████      | 10928/20010 [46:02<42:24,  3.57batch/s]Batch 10800/20010 Done, mean position loss: 25.240763235092164\n",
      "Training growing_up:  54%|███████      | 10889/20010 [46:04<37:09,  4.09batch/s]Batch 10800/20010 Done, mean position loss: 25.04237340927124\n",
      "Training growing_up:  54%|██████▉      | 10761/20010 [46:07<40:58,  3.76batch/s]Batch 10900/20010 Done, mean position loss: 24.642431144714358\n",
      "Training growing_up:  55%|███████▏     | 10989/20010 [46:17<37:33,  4.00batch/s]Batch 10800/20010 Done, mean position loss: 24.76807222366333\n",
      "Training growing_up:  55%|███████      | 10949/20010 [46:20<37:14,  4.05batch/s]Batch 11000/20010 Done, mean position loss: 25.577406742572784\n",
      "Training growing_up:  54%|███████      | 10839/20010 [46:27<39:10,  3.90batch/s]Batch 10900/20010 Done, mean position loss: 25.544528584480286\n",
      "Training growing_up:  55%|███████      | 10909/20010 [46:30<40:31,  3.74batch/s]Batch 10900/20010 Done, mean position loss: 24.976792006492616\n",
      "Training growing_up:  55%|███████▏     | 11050/20010 [46:33<36:36,  4.08batch/s]Batch 11000/20010 Done, mean position loss: 24.751104104518888\n",
      "Training growing_up:  55%|███████      | 10961/20010 [46:43<40:47,  3.70batch/s]Batch 10900/20010 Done, mean position loss: 25.245018625259398\n",
      "Training growing_up:  55%|███████▏     | 10971/20010 [46:46<38:14,  3.94batch/s]Batch 11100/20010 Done, mean position loss: 25.514138677120208\n",
      "Training growing_up:  55%|███████▏     | 10992/20010 [46:53<37:41,  3.99batch/s]Batch 11000/20010 Done, mean position loss: 25.338852689266204\n",
      "Training growing_up:  55%|███████▏     | 11088/20010 [46:55<37:33,  3.96batch/s]Batch 11000/20010 Done, mean position loss: 25.764488792419435\n",
      "Training growing_up:  55%|███████      | 10959/20010 [46:59<37:05,  4.07batch/s]Batch 11100/20010 Done, mean position loss: 24.731075367927552\n",
      "Training growing_up:  56%|███████▎     | 11193/20010 [47:09<35:16,  4.17batch/s]Batch 11000/20010 Done, mean position loss: 25.242790915966033\n",
      "Training growing_up:  55%|███████▏     | 11070/20010 [47:11<38:36,  3.86batch/s]Batch 11200/20010 Done, mean position loss: 26.23632115364075\n",
      "Training growing_up:  55%|███████▏     | 11088/20010 [47:19<38:00,  3.91batch/s]Batch 11100/20010 Done, mean position loss: 24.823859162330628\n",
      "Training growing_up:  56%|███████▎     | 11242/20010 [47:22<35:18,  4.14batch/s]Batch 11100/20010 Done, mean position loss: 25.877590243816375\n",
      "Training growing_up:  56%|███████▏     | 11107/20010 [47:24<41:02,  3.62batch/s]Batch 11200/20010 Done, mean position loss: 24.509245612621307\n",
      "Training growing_up:  56%|███████▏     | 11150/20010 [47:36<36:10,  4.08batch/s]Batch 11100/20010 Done, mean position loss: 24.969905300140383\n",
      "Training growing_up:  56%|███████▏     | 11154/20010 [47:37<37:59,  3.89batch/s]Batch 11300/20010 Done, mean position loss: 25.661429603099823\n",
      "Training growing_up:  56%|███████▏     | 11136/20010 [47:45<39:33,  3.74batch/s]Batch 11200/20010 Done, mean position loss: 25.700750768184662\n",
      "Training growing_up:  56%|███████▎     | 11293/20010 [47:48<34:24,  4.22batch/s]Batch 11200/20010 Done, mean position loss: 25.288782532215116\n",
      "Training growing_up:  56%|███████▏     | 11158/20010 [47:50<35:45,  4.13batch/s]Batch 11300/20010 Done, mean position loss: 24.65679969549179\n",
      "Training growing_up:  57%|███████▎     | 11339/20010 [48:01<41:26,  3.49batch/s]Batch 11200/20010 Done, mean position loss: 25.503509933948514\n",
      "Training growing_up:  57%|███████▎     | 11340/20010 [48:02<40:42,  3.55batch/s]Batch 11400/20010 Done, mean position loss: 26.098511328697207\n",
      "Training growing_up:  57%|███████▍     | 11380/20010 [48:13<40:47,  3.53batch/s]Batch 11300/20010 Done, mean position loss: 25.01713599205017\n",
      "Training growing_up:  57%|███████▎     | 11313/20010 [48:17<41:34,  3.49batch/s]Batch 11300/20010 Done, mean position loss: 24.700552299022675\n",
      "Training growing_up:  56%|███████▎     | 11261/20010 [48:19<45:41,  3.19batch/s]Batch 11400/20010 Done, mean position loss: 25.426578752994537\n",
      "Training growing_up:  57%|███████▍     | 11360/20010 [48:30<39:52,  3.62batch/s]Batch 11500/20010 Done, mean position loss: 25.530698709487915\n",
      "Training growing_up:  57%|███████▍     | 11501/20010 [48:31<48:49,  2.90batch/s]Batch 11300/20010 Done, mean position loss: 25.315758986473085\n",
      "Training growing_up:  57%|███████▎     | 11339/20010 [48:42<41:59,  3.44batch/s]Batch 11400/20010 Done, mean position loss: 25.486145639419554\n",
      "Training growing_up:  57%|███████▍     | 11352/20010 [48:46<43:59,  3.28batch/s]Batch 11400/20010 Done, mean position loss: 24.801090919971465\n",
      "Training growing_up:  57%|███████▍     | 11407/20010 [48:48<40:37,  3.53batch/s]Batch 11500/20010 Done, mean position loss: 24.56999665975571\n",
      "Training growing_up:  57%|███████▍     | 11445/20010 [48:59<41:56,  3.40batch/s]Batch 11600/20010 Done, mean position loss: 25.368765568733217\n",
      "Training growing_up:  57%|███████▍     | 11449/20010 [49:00<38:59,  3.66batch/s]Batch 11400/20010 Done, mean position loss: 24.83024424314499\n",
      "Training growing_up:  58%|███████▌     | 11643/20010 [49:11<38:17,  3.64batch/s]Batch 11500/20010 Done, mean position loss: 25.725408792495728\n",
      "Training growing_up:  58%|███████▌     | 11656/20010 [49:14<39:00,  3.57batch/s]Batch 11500/20010 Done, mean position loss: 25.209940421581265\n",
      "Training growing_up:  58%|███████▌     | 11664/20010 [49:17<39:14,  3.55batch/s]Batch 11600/20010 Done, mean position loss: 25.396035654544832\n",
      "Training growing_up:  58%|███████▍     | 11544/20010 [49:27<42:52,  3.29batch/s]Batch 11700/20010 Done, mean position loss: 25.83886444091797\n",
      "Training growing_up:  58%|███████▌     | 11705/20010 [49:28<41:13,  3.36batch/s]Batch 11500/20010 Done, mean position loss: 24.54008900165558\n",
      "Training growing_up:  58%|███████▌     | 11588/20010 [49:39<40:24,  3.47batch/s]Batch 11600/20010 Done, mean position loss: 24.568113882541656\n",
      "Training growing_up:  59%|███████▋     | 11757/20010 [49:43<37:41,  3.65batch/s]Batch 11600/20010 Done, mean position loss: 24.684204621315004\n",
      "Training growing_up:  58%|███████▌     | 11608/20010 [49:45<39:33,  3.54batch/s]Batch 11700/20010 Done, mean position loss: 24.46904412508011\n",
      "Training growing_up:  58%|███████▌     | 11594/20010 [49:55<42:07,  3.33batch/s]Batch 11800/20010 Done, mean position loss: 26.330870299339296\n",
      "Training growing_up:  58%|███████▌     | 11662/20010 [49:57<40:36,  3.43batch/s]Batch 11600/20010 Done, mean position loss: 24.718418765068055\n",
      "Training growing_up:  59%|███████▋     | 11779/20010 [50:08<39:34,  3.47batch/s]Batch 11700/20010 Done, mean position loss: 24.453717713356017\n",
      "Training growing_up:  58%|███████▌     | 11651/20010 [50:12<39:17,  3.55batch/s]Batch 11700/20010 Done, mean position loss: 24.31565478086472\n",
      "Training growing_up:  59%|███████▌     | 11708/20010 [50:14<38:52,  3.56batch/s]Batch 11800/20010 Done, mean position loss: 25.012164351940157\n",
      "Training growing_up:  59%|███████▋     | 11741/20010 [50:24<38:31,  3.58batch/s]Batch 11900/20010 Done, mean position loss: 25.112977707386015\n",
      "Training growing_up:  60%|███████▋     | 11909/20010 [50:26<37:05,  3.64batch/s]Batch 11700/20010 Done, mean position loss: 24.187121970653536\n",
      "Training growing_up:  59%|███████▋     | 11737/20010 [50:37<40:27,  3.41batch/s]Batch 11800/20010 Done, mean position loss: 24.704053015708922\n",
      "Training growing_up:  59%|███████▋     | 11893/20010 [50:41<37:56,  3.57batch/s]Batch 11800/20010 Done, mean position loss: 25.801058282852175\n",
      "Training growing_up:  59%|███████▋     | 11822/20010 [50:43<38:44,  3.52batch/s]Batch 11900/20010 Done, mean position loss: 24.14768611431122\n",
      "Training growing_up:  59%|███████▋     | 11790/20010 [50:52<38:38,  3.55batch/s]Batch 12000/20010 Done, mean position loss: 25.62982153892517\n",
      "Training growing_up:  60%|███████▊     | 11941/20010 [50:55<37:45,  3.56batch/s]Batch 11800/20010 Done, mean position loss: 24.794586639404294\n",
      "Training growing_up:  59%|███████▋     | 11886/20010 [51:05<41:24,  3.27batch/s]Batch 11900/20010 Done, mean position loss: 25.29582176923752\n",
      "Training growing_up:  60%|███████▊     | 12063/20010 [51:10<37:37,  3.52batch/s]Batch 11900/20010 Done, mean position loss: 24.741940522193907\n",
      "Training growing_up:  60%|███████▋     | 11908/20010 [51:12<38:15,  3.53batch/s]Batch 12000/20010 Done, mean position loss: 24.43455929994583\n",
      "Training growing_up:  59%|███████▋     | 11888/20010 [51:20<38:41,  3.50batch/s]Batch 12100/20010 Done, mean position loss: 25.07580892086029\n",
      "Training growing_up:  60%|███████▊     | 11964/20010 [51:24<37:56,  3.53batch/s]Batch 11900/20010 Done, mean position loss: 24.319076581001283\n",
      "Training growing_up:  61%|███████▉     | 12150/20010 [51:34<36:00,  3.64batch/s]Batch 12000/20010 Done, mean position loss: 24.678642950057984\n",
      "Training growing_up:  60%|███████▊     | 12014/20010 [51:38<37:42,  3.53batch/s]Batch 12000/20010 Done, mean position loss: 24.86604743003845\n",
      "Training growing_up:  61%|███████▉     | 12173/20010 [51:41<36:17,  3.60batch/s]Batch 12100/20010 Done, mean position loss: 24.669044744968414\n",
      "Training growing_up:  60%|███████▊     | 12050/20010 [51:48<37:05,  3.58batch/s]Batch 12200/20010 Done, mean position loss: 25.550127315521237\n",
      "Training growing_up:  60%|███████▊     | 12064/20010 [51:52<37:40,  3.52batch/s]Batch 12000/20010 Done, mean position loss: 25.364726734161376\n",
      "Training growing_up:  61%|███████▉     | 12178/20010 [52:03<39:07,  3.34batch/s]Batch 12100/20010 Done, mean position loss: 24.35993703365326\n",
      "Training growing_up:  61%|███████▊     | 12114/20010 [52:07<37:32,  3.51batch/s]Batch 12100/20010 Done, mean position loss: 25.424454200267792\n",
      "Training growing_up:  60%|███████▊     | 12058/20010 [52:09<37:57,  3.49batch/s]Batch 12200/20010 Done, mean position loss: 24.900295078754425\n",
      "Training growing_up:  61%|███████▉     | 12226/20010 [52:17<35:59,  3.60batch/s]Batch 12300/20010 Done, mean position loss: 26.094269349575043\n",
      "Training growing_up:  61%|███████▉     | 12243/20010 [52:21<35:17,  3.67batch/s]Batch 12100/20010 Done, mean position loss: 24.951835143566132\n",
      "Training growing_up:  62%|████████     | 12353/20010 [52:32<37:49,  3.37batch/s]Batch 12200/20010 Done, mean position loss: 24.858344473838805\n",
      "Training growing_up:  61%|███████▉     | 12214/20010 [52:36<36:15,  3.58batch/s]Batch 12200/20010 Done, mean position loss: 25.199577100276947\n",
      "Training growing_up:  62%|████████     | 12376/20010 [52:38<34:44,  3.66batch/s]Batch 12300/20010 Done, mean position loss: 24.00726086139679\n",
      "Training growing_up:  61%|███████▉     | 12247/20010 [52:45<36:47,  3.52batch/s]Batch 12400/20010 Done, mean position loss: 25.313325622081756\n",
      "Training growing_up:  61%|███████▉     | 12253/20010 [52:51<38:42,  3.34batch/s]Batch 12200/20010 Done, mean position loss: 24.475715987682342\n",
      "Training growing_up:  62%|████████     | 12378/20010 [53:00<38:02,  3.34batch/s]Batch 12300/20010 Done, mean position loss: 24.641568179130555\n",
      "Training growing_up:  62%|████████     | 12314/20010 [53:04<36:02,  3.56batch/s]Batch 12300/20010 Done, mean position loss: 25.2049463391304\n",
      "Training growing_up:  62%|███████▉     | 12308/20010 [53:07<36:19,  3.53batch/s]Batch 12400/20010 Done, mean position loss: 24.707584793567655\n",
      "Training growing_up:  62%|████████     | 12423/20010 [53:13<35:08,  3.60batch/s]Batch 12500/20010 Done, mean position loss: 25.263331561088563\n",
      "Training growing_up:  62%|████████     | 12369/20010 [53:20<38:25,  3.31batch/s]Batch 12300/20010 Done, mean position loss: 24.734395763874055\n",
      "Training growing_up:  62%|████████     | 12331/20010 [53:29<36:36,  3.50batch/s]Batch 12400/20010 Done, mean position loss: 24.589249138832095\n",
      "Training growing_up:  63%|████████▏    | 12570/20010 [53:33<36:21,  3.41batch/s]Batch 12400/20010 Done, mean position loss: 24.86910702943802\n",
      "Training growing_up:  62%|████████     | 12353/20010 [53:35<39:14,  3.25batch/s]Batch 12500/20010 Done, mean position loss: 24.170439434051513\n",
      "Training growing_up:  63%|████████▏    | 12522/20010 [53:42<35:28,  3.52batch/s]Batch 12600/20010 Done, mean position loss: 25.115601789951324\n",
      "Training growing_up:  63%|████████▏    | 12626/20010 [53:49<32:57,  3.73batch/s]Batch 12400/20010 Done, mean position loss: 24.093942422866824\n",
      "Training growing_up:  63%|████████▏    | 12657/20010 [53:58<34:06,  3.59batch/s]Batch 12500/20010 Done, mean position loss: 24.03771610021591\n",
      "Training growing_up:  63%|████████▏    | 12592/20010 [54:02<34:39,  3.57batch/s]Batch 12500/20010 Done, mean position loss: 24.51210909605026\n",
      "Training growing_up:  63%|████████▏    | 12509/20010 [54:04<34:57,  3.58batch/s]Batch 12600/20010 Done, mean position loss: 24.537069396972655\n",
      "Training growing_up:  62%|████████     | 12472/20010 [54:10<35:44,  3.52batch/s]Batch 12700/20010 Done, mean position loss: 24.896897518634795\n",
      "Training growing_up:  63%|████████▏    | 12572/20010 [54:18<35:08,  3.53batch/s]Batch 12500/20010 Done, mean position loss: 24.499131946563722\n",
      "Training growing_up:  63%|████████▏    | 12586/20010 [54:26<37:14,  3.32batch/s]Batch 12600/20010 Done, mean position loss: 24.684218091964723\n",
      "Training growing_up:  63%|████████▏    | 12596/20010 [54:29<35:42,  3.46batch/s]"
     ]
    }
   ],
   "source": [
    "trainall = 1\n",
    "network_siz = 128\n",
    "n_networks = 5\n",
    "train_random = 0 \n",
    "start_again = 1\n",
    "\n",
    "!python ../model.py {trainall} {network_siz} {n_networks} {train_random} {start_again}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib qt\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "fontsize_label = 18\n",
    "fontsize_tick = 15\n",
    "fontsize_legend = 20\n",
    "\n",
    "palette_colors = {'FF1': 'g', 'FF2': 'r', 'NF1': 'k', 'NF2': 'k'}\n",
    "\n",
    "\n",
    "base_dir = os.path.join(os.path.expanduser('~'),'Documents','Data','MotorNet')\n",
    "save_fig = '/Users/mahdiyar/Diedrichsenlab Dropbox/Mahdiyar Shahbazi/Conferences/NCM2024_Mahdiyar/figures'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from get_utils import get_loss\n",
    "from plot import plot_learning\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "folder_name = 'Sim_simp_16'\n",
    "\n",
    "\n",
    "num_model = 40\n",
    "phases = {'NF1':[0],'FF1':[8],'NF2':[0],'FF2':[8]}\n",
    "loss_type = 'lateral'\n",
    "\n",
    "loss = get_loss(folder_name,num_model,phases,loss_type=loss_type,w=1,target=None)\n",
    "\n",
    "\n",
    "# fig, ax = plot_learning(loss,figsize=(10,5),show_saving=True,gap=5000,palette_colors=palette_colors)\n",
    "\n",
    "\n",
    "\n",
    "# ax[0].set_xlabel('# Batches', fontsize = fontsize_label)\n",
    "# ax[0].set_ylabel('Position loss [mm]', fontsize = fontsize_label)\n",
    "# ax[0].legend(title = '',frameon = False, bbox_to_anchor= (1,1), fontsize=fontsize_legend)\n",
    "# ax[0].legend().set_visible(False)\n",
    "# ax[0].xaxis.set_tick_params(labelsize=fontsize_tick)\n",
    "# ax[0].yaxis.set_tick_params(labelsize=fontsize_tick)\n",
    "\n",
    "# ax[0].spines['top'].set_visible(False)\n",
    "# ax[0].spines['right'].set_visible(False)\n",
    "# plt.tick_params(left = False) \n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# #fig.savefig(os.path.join(save_fig,'learnings.pdf'),dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Barplots for savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss['FF2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10001,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(loss['NF1'], axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2801"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss['NF1'][19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
